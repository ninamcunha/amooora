{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07016fe-6215-48a0-a685-8c905e4e4357",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# categorical_cols = ['status', 'sex', 'orientation', 'body_type', 'diet', 'drinks', 'drugs',\n",
    "#                     'education', 'ethnicity', 'job', 'location', 'smokes', 'religion', 'sign', 'pets']\n",
    "\n",
    "\n",
    "# label_encoding_cols = ['education', 'ethnicity', 'job', 'location', 'sign']\n",
    "\n",
    "\n",
    "# label_encoders = {}\n",
    "# for col in label_encoding_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     df[col] = le.fit_transform(df[col].astype(str))  # Convert to string to avoid NaN issues\n",
    "#     label_encoders[col] = le  # Save the encoder in case you need to decode later\n",
    "\n",
    "\n",
    "# df = pd.get_dummies(df, columns=[col for col in categorical_cols if col not in label_encoding_cols], drop_first=True)\n",
    "\n",
    "\n",
    "# encoded_file_path = \"okcupid_profiles_encoded.csv\"  # Output file path\n",
    "# df.to_csv(encoded_file_path, index=False)\n",
    "\n",
    "# print(f\"Dataset with encoding saved at: {encoded_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46ba6f-ae1b-40a9-9f26-e89cebc61f93",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Amooora text data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc544f77-1251-4f12-9c31-977561f3774d",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Import libraries and load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cbb7225-da96-41f9-a48d-54545a509f7a",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b46a83-7734-407d-bbd8-365b8fb49cc2",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m..\u001b[0m\r\n",
      "├── \u001b[01;34mnotebooks\u001b[0m\r\n",
      "│   └── dedemenezes_exploratory.ipynb\r\n",
      "├── \u001b[01;34mraw_data\u001b[0m\r\n",
      "│   ├── okcupid_profiles.csv\r\n",
      "│   ├── okcupid_profiles_encoded.csv\r\n",
      "│   ├── \u001b[01;32mparsed_data_public.csv\u001b[0m\r\n",
      "│   ├── \u001b[01;32mquestion_data.csv\u001b[0m\r\n",
      "│   └── \u001b[01;32muser_data_public.csv\u001b[0m\r\n",
      "├── README.md\r\n",
      "└── requirements.txt\r\n",
      "\r\n",
      "2 directories, 8 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae74d9de-6bc2-4cac-8c09-cff9df9b0d24",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/okcupid_profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa890203-d9fd-4a55-8221-fe8b4463ff3e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc076a3a-7275-41c3-b5fb-a44dd59c86af",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  status sex orientation       body_type               diet    drinks  \\\n",
       "0   22  single   m    straight  a little extra  strictly anything  socially   \n",
       "1   35  single   m    straight         average       mostly other     often   \n",
       "\n",
       "       drugs                      education     ethnicity  ...  \\\n",
       "0      never  working on college/university  asian, white  ...   \n",
       "1  sometimes          working on space camp         white  ...   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:  i would love to think that i was so...   \n",
       "1  i am a chef: this is what that means. 1. i am ...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh. ranting about a good salt...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books: absurdistan, the republic, of mice and ...   \n",
       "1  i am die hard christopher moore fan. i don't r...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0                  food. water. cell phone. shelter.   \n",
       "1  delicious porkness in all of its glories. my b...   \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                          NaN   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "1  i am very open and will share just about anyth...   \n",
       "\n",
       "                                              essay9  \n",
       "0  you want to be swept off your feet! you are ti...  \n",
       "1                                                NaN  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4591acf-a7b0-4bb4-8854-9c402893d3ae",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Access Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210efa5b",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>2012-06-28-14-22</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn't want kids</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>2012-06-27-21-26</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>59</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>sales / marketing / biz dev</td>\n",
       "      <td>2012-06-12-21-47</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>has kids</td>\n",
       "      <td>has dogs</td>\n",
       "      <td>catholicism but not too serious about it</td>\n",
       "      <td>cancer and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white, other</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>entertainment / media</td>\n",
       "      <td>2012-06-29-11-01</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>doesn't have kids</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>leo but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>asian</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>construction / craftsmanship</td>\n",
       "      <td>2012-06-27-23-37</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids</td>\n",
       "      <td>NaN</td>\n",
       "      <td>christianity but not too serious about it</td>\n",
       "      <td>sagittarius but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, black</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>medicine / health</td>\n",
       "      <td>2012-06-23-13-01</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>doesn't have kids, but wants them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>leo and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>trying to quit</td>\n",
       "      <td>english (fluently), spanish (poorly), chinese ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>39</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>gay</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>medicine / health</td>\n",
       "      <td>2012-06-29-00-42</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>catholicism and laughing about it</td>\n",
       "      <td>gemini and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     status sex orientation       body_type               diet  \\\n",
       "0       22     single   m    straight  a little extra  strictly anything   \n",
       "1       35     single   m    straight         average       mostly other   \n",
       "2       38  available   m    straight            thin           anything   \n",
       "3       23     single   m    straight            thin         vegetarian   \n",
       "4       29     single   m    straight        athletic                NaN   \n",
       "...    ...        ...  ..         ...             ...                ...   \n",
       "59941   59     single   f    straight             NaN                NaN   \n",
       "59942   24     single   m    straight             fit    mostly anything   \n",
       "59943   42     single   m    straight         average    mostly anything   \n",
       "59944   27     single   m    straight        athletic    mostly anything   \n",
       "59945   39     single   m         gay         average                NaN   \n",
       "\n",
       "           drinks      drugs                          education  \\\n",
       "0        socially      never      working on college/university   \n",
       "1           often  sometimes              working on space camp   \n",
       "2        socially        NaN     graduated from masters program   \n",
       "3        socially        NaN      working on college/university   \n",
       "4        socially      never  graduated from college/university   \n",
       "...           ...        ...                                ...   \n",
       "59941    socially      never  graduated from college/university   \n",
       "59942       often  sometimes      working on college/university   \n",
       "59943  not at all      never     graduated from masters program   \n",
       "59944    socially      often      working on college/university   \n",
       "59945    socially        NaN     graduated from masters program   \n",
       "\n",
       "                 ethnicity  ...  income                           job  \\\n",
       "0             asian, white  ...      -1                transportation   \n",
       "1                    white  ...   80000          hospitality / travel   \n",
       "2                      NaN  ...      -1                           NaN   \n",
       "3                    white  ...   20000                       student   \n",
       "4      asian, black, other  ...      -1   artistic / musical / writer   \n",
       "...                    ...  ...     ...                           ...   \n",
       "59941                  NaN  ...      -1   sales / marketing / biz dev   \n",
       "59942         white, other  ...      -1         entertainment / media   \n",
       "59943                asian  ...  100000  construction / craftsmanship   \n",
       "59944         asian, black  ...      -1             medicine / health   \n",
       "59945                white  ...      -1             medicine / health   \n",
       "\n",
       "            last_online                         location  \\\n",
       "0      2012-06-28-20-30  south san francisco, california   \n",
       "1      2012-06-29-21-41              oakland, california   \n",
       "2      2012-06-27-09-10        san francisco, california   \n",
       "3      2012-06-28-14-22             berkeley, california   \n",
       "4      2012-06-27-21-26        san francisco, california   \n",
       "...                 ...                              ...   \n",
       "59941  2012-06-12-21-47              oakland, california   \n",
       "59942  2012-06-29-11-01        san francisco, california   \n",
       "59943  2012-06-27-23-37  south san francisco, california   \n",
       "59944  2012-06-23-13-01        san francisco, california   \n",
       "59945  2012-06-29-00-42        san francisco, california   \n",
       "\n",
       "                                    offspring                       pets  \\\n",
       "0      doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "1      doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "2                                         NaN                   has cats   \n",
       "3                           doesn't want kids                 likes cats   \n",
       "4                                         NaN  likes dogs and likes cats   \n",
       "...                                       ...                        ...   \n",
       "59941                                has kids                   has dogs   \n",
       "59942                       doesn't have kids  likes dogs and likes cats   \n",
       "59943                       doesn't have kids                        NaN   \n",
       "59944       doesn't have kids, but wants them  likes dogs and likes cats   \n",
       "59945                                     NaN  likes dogs and likes cats   \n",
       "\n",
       "                                        religion  \\\n",
       "0          agnosticism and very serious about it   \n",
       "1       agnosticism but not too serious about it   \n",
       "2                                            NaN   \n",
       "3                                            NaN   \n",
       "4                                            NaN   \n",
       "...                                          ...   \n",
       "59941   catholicism but not too serious about it   \n",
       "59942                                agnosticism   \n",
       "59943  christianity but not too serious about it   \n",
       "59944   agnosticism but not too serious about it   \n",
       "59945          catholicism and laughing about it   \n",
       "\n",
       "                                           sign          smokes  \\\n",
       "0                                        gemini       sometimes   \n",
       "1                                        cancer              no   \n",
       "2            pisces but it doesn&rsquo;t matter              no   \n",
       "3                                        pisces              no   \n",
       "4                                      aquarius              no   \n",
       "...                                         ...             ...   \n",
       "59941  cancer and it&rsquo;s fun to think about              no   \n",
       "59942           leo but it doesn&rsquo;t matter              no   \n",
       "59943   sagittarius but it doesn&rsquo;t matter              no   \n",
       "59944     leo and it&rsquo;s fun to think about  trying to quit   \n",
       "59945  gemini and it&rsquo;s fun to think about       sometimes   \n",
       "\n",
       "                                                  speaks  \n",
       "0                                                english  \n",
       "1      english (fluently), spanish (poorly), french (...  \n",
       "2                                   english, french, c++  \n",
       "3                               english, german (poorly)  \n",
       "4                                                english  \n",
       "...                                                  ...  \n",
       "59941                                            english  \n",
       "59942                                 english (fluently)  \n",
       "59943                                 english (fluently)  \n",
       "59944  english (fluently), spanish (poorly), chinese ...  \n",
       "59945                                            english  \n",
       "\n",
       "[59946 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, :21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc47a3f-6746-4331-9ec8-b6afe3acef41",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "text_df = df.iloc[:, 21:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd5c95d-0126-4806-ab2f-668c28622044",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>viewing. listening. dancing. talking. drinking...</td>\n",
       "      <td>when i was five years old, i was known as \"the...</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . . lynch, jarmusch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you feel so inclined.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at: http://bagsbrown....</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians at the moment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              essay0  \\\n",
       "0  about me:  i would love to think that i was so...   \n",
       "1  i am a chef: this is what that means. 1. i am ...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh. ranting about a good salt...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at: http://bagsbrown....   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "1                                                NaN   \n",
       "2  my large jaw and large glasses are the physica...   \n",
       "3                  socially awkward but i do my best   \n",
       "4            i smile a lot and my inquisitive nature   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books: absurdistan, the republic, of mice and ...   \n",
       "1  i am die hard christopher moore fan. i don't r...   \n",
       "2  okay this is where the cultural matrix gets so...   \n",
       "3  bataille, celine, beckett. . . lynch, jarmusch...   \n",
       "4  music: bands, rappers, musicians at the moment...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0                  food. water. cell phone. shelter.   \n",
       "1  delicious porkness in all of its glories. my b...   \n",
       "2  movement conversation creation contemplation t...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "3   cats and german philosophy   \n",
       "4                          NaN   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "1                                                NaN   \n",
       "2  viewing. listening. dancing. talking. drinking...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "1  i am very open and will share just about anyth...   \n",
       "2  when i was five years old, i was known as \"the...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay9  \n",
       "0  you want to be swept off your feet! you are ti...  \n",
       "1                                                NaN  \n",
       "2  you are bright, open, intense, silly, ironic, ...  \n",
       "3                              you feel so inclined.  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2440c5-48c0-4ce8-8624-342799de5cab",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Checking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceddae46-534a-4b6a-a1fe-c86b4f7e31d8",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   essay0  54458 non-null  object\n",
      " 1   essay1  52374 non-null  object\n",
      " 2   essay2  50308 non-null  object\n",
      " 3   essay3  48470 non-null  object\n",
      " 4   essay4  49409 non-null  object\n",
      " 5   essay5  49096 non-null  object\n",
      " 6   essay6  46175 non-null  object\n",
      " 7   essay7  47495 non-null  object\n",
      " 8   essay8  40721 non-null  object\n",
      " 9   essay9  47343 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "text_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec7e89-f843-4c95-9467-6260b2d8d474",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "298ae729-0ac6-4479-9b34-7115f2d1054e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2134)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a72a264f-f192-4561-8bda-9f2278558166",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59757</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59791</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59857</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59881</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2134 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay0 essay1 essay2 essay3 essay4 essay5 essay6 essay7 essay8 essay9\n",
       "51       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "64       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "80       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "84       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "175      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
       "59757    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "59791    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "59857    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "59881    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "59930    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "\n",
       "[2134 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[text_df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d63151-5d50-44ec-b735-c967e2e259bf",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "We have `2134`duplicated observations all made of empty answers to all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d4a646e-3c16-4940-a897-7c09ebcae603",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# no_dup_df = text_df.drop_duplicates()\n",
    "# no_dup_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3de282-1190-4193-86b6-5c08315a59b6",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a2b6ffa-b005-48bd-a2f4-e892bc050dc6",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay8    32.070530\n",
       "essay6    22.972342\n",
       "essay9    21.023922\n",
       "essay7    20.770360\n",
       "essay3    19.143896\n",
       "essay5    18.099623\n",
       "essay4    17.577486\n",
       "essay2    16.077803\n",
       "essay1    12.631368\n",
       "essay0     9.154906\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.isnull().sum().sort_values(ascending=False) / len(text_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30fd8b36-acdd-47a0-b0b4-a8faf7f39f4d",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29866, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19284151",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e0861",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Drop is not an option!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfe4be",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## % of answered questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78726366",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6',\n",
       "       'essay7', 'essay8', 'essay9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a6190a0",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "text_df['not_answered_percent'] = text_df.apply(lambda x: x.isna().sum() / len(text_df.columns) * 100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc66bdad",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "      <th>not_answered_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>viewing. listening. dancing. talking. drinking...</td>\n",
       "      <td>when i was five years old, i was known as \"the...</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, ...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . . lynch, jarmusch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you feel so inclined.</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at: http://bagsbrown....</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians at the moment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>vibrant, expressive, caring optimist. i love b...</td>\n",
       "      <td>the happiest times have been when life came to...</td>\n",
       "      <td>i make an outstanding osso bucco. i am also ve...</td>\n",
       "      <td>i am told that people notice my smile, eyes an...</td>\n",
       "      <td>i am an avid movie watcher and follow the broa...</td>\n",
       "      <td>my family, my dog, italy, words and music!</td>\n",
       "      <td>writing my book.</td>\n",
       "      <td>running with my dog, finishing up the work wee...</td>\n",
       "      <td>i have a dream to sing at the alconquin in nyc...</td>\n",
       "      <td>you are seeking a long term connection of shar...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>i'm nick. i never know what to write about mys...</td>\n",
       "      <td>currently finishing school for film production...</td>\n",
       "      <td>filmmaking, photography, graphic design, web d...</td>\n",
       "      <td>dude, i don't know.</td>\n",
       "      <td>movies: hook (the greatest adventure ever!), g...</td>\n",
       "      <td>iphone contact lenses headphones camera tv rem...</td>\n",
       "      <td>i do most of my thinking on the bus to/from wo...</td>\n",
       "      <td>bringin' home bacon, or drinking and shakin'!</td>\n",
       "      <td>when i was 18 i got a tattoo of waldo somewher...</td>\n",
       "      <td>meh if you made it this far you might as well.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>hello! i enjoy traveling, watching movies, and...</td>\n",
       "      <td>i'm a civil engineer, who enjoys helping the c...</td>\n",
       "      <td>- looking at things objectively - getting thin...</td>\n",
       "      <td>i'm quiet until i get used to the environment ...</td>\n",
       "      <td>last book: \"game change\". movies: bourne serie...</td>\n",
       "      <td>- iphone - friends and family - internet - bay...</td>\n",
       "      <td>aside from work, how to improve my home.</td>\n",
       "      <td>out enjoying friendly conversation over dinner.</td>\n",
       "      <td>please let me think about this more.</td>\n",
       "      <td>we have similar interests.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>\"all i have in this world are my balls and my ...</td>\n",
       "      <td>following my dreams... \"you got a dream... you...</td>\n",
       "      <td>listening</td>\n",
       "      <td>it used to be the hair until i mowed it off bu...</td>\n",
       "      <td>where to begin musically: right now i listen t...</td>\n",
       "      <td>music, family, friends, a basketball, hoop, so...</td>\n",
       "      <td>what can i do to make someone chuckle....</td>\n",
       "      <td>what i would do on any other day. everydays a ...</td>\n",
       "      <td>i like walking around in other people's house ...</td>\n",
       "      <td>you are interested and interesting...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>is it odd that having a little \"enemy\" status ...</td>\n",
       "      <td>i work with elderly people (psychotherapy and ...</td>\n",
       "      <td>i'm a great bullshitter. i don't know what it ...</td>\n",
       "      <td>either that i am funny/sarcastic, or that i am...</td>\n",
       "      <td>i just read the help by kathryn stockett, sooo...</td>\n",
       "      <td>1. family &amp; friends &amp; other humans - interacti...</td>\n",
       "      <td>sex, myself, other people, how amazing everyth...</td>\n",
       "      <td>out at happy hour with my friends, running int...</td>\n",
       "      <td>i wish i could cry like holly hunter in broadc...</td>\n",
       "      <td>if you have a back-bone, an opinion, a sense o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay0  \\\n",
       "0      about me:  i would love to think that i was so...   \n",
       "1      i am a chef: this is what that means. 1. i am ...   \n",
       "2      i'm not ashamed of much, but writing public te...   \n",
       "3              i work in a library and go to school. . .   \n",
       "4      hey how's it going? currently vague on the pro...   \n",
       "...                                                  ...   \n",
       "59941  vibrant, expressive, caring optimist. i love b...   \n",
       "59942  i'm nick. i never know what to write about mys...   \n",
       "59943  hello! i enjoy traveling, watching movies, and...   \n",
       "59944  \"all i have in this world are my balls and my ...   \n",
       "59945  is it odd that having a little \"enemy\" status ...   \n",
       "\n",
       "                                                  essay1  \\\n",
       "0      currently working as an international agent fo...   \n",
       "1      dedicating everyday to being an unbelievable b...   \n",
       "2      i make nerdy software for musicians, artists, ...   \n",
       "3              reading things written by old dead people   \n",
       "4                             work work work work + play   \n",
       "...                                                  ...   \n",
       "59941  the happiest times have been when life came to...   \n",
       "59942  currently finishing school for film production...   \n",
       "59943  i'm a civil engineer, who enjoys helping the c...   \n",
       "59944  following my dreams... \"you got a dream... you...   \n",
       "59945  i work with elderly people (psychotherapy and ...   \n",
       "\n",
       "                                                  essay2  \\\n",
       "0      making people laugh. ranting about a good salt...   \n",
       "1      being silly. having ridiculous amonts of fun w...   \n",
       "2      improvising in different contexts. alternating...   \n",
       "3      playing synthesizers and organizing books acco...   \n",
       "4      creating imagery to look at: http://bagsbrown....   \n",
       "...                                                  ...   \n",
       "59941  i make an outstanding osso bucco. i am also ve...   \n",
       "59942  filmmaking, photography, graphic design, web d...   \n",
       "59943  - looking at things objectively - getting thin...   \n",
       "59944                                          listening   \n",
       "59945  i'm a great bullshitter. i don't know what it ...   \n",
       "\n",
       "                                                  essay3  \\\n",
       "0      the way i look. i am a six foot half asian, ha...   \n",
       "1                                                    NaN   \n",
       "2      my large jaw and large glasses are the physica...   \n",
       "3                      socially awkward but i do my best   \n",
       "4                i smile a lot and my inquisitive nature   \n",
       "...                                                  ...   \n",
       "59941  i am told that people notice my smile, eyes an...   \n",
       "59942                                dude, i don't know.   \n",
       "59943  i'm quiet until i get used to the environment ...   \n",
       "59944  it used to be the hair until i mowed it off bu...   \n",
       "59945  either that i am funny/sarcastic, or that i am...   \n",
       "\n",
       "                                                  essay4  \\\n",
       "0      books: absurdistan, the republic, of mice and ...   \n",
       "1      i am die hard christopher moore fan. i don't r...   \n",
       "2      okay this is where the cultural matrix gets so...   \n",
       "3      bataille, celine, beckett. . . lynch, jarmusch...   \n",
       "4      music: bands, rappers, musicians at the moment...   \n",
       "...                                                  ...   \n",
       "59941  i am an avid movie watcher and follow the broa...   \n",
       "59942  movies: hook (the greatest adventure ever!), g...   \n",
       "59943  last book: \"game change\". movies: bourne serie...   \n",
       "59944  where to begin musically: right now i listen t...   \n",
       "59945  i just read the help by kathryn stockett, sooo...   \n",
       "\n",
       "                                                  essay5  \\\n",
       "0                      food. water. cell phone. shelter.   \n",
       "1      delicious porkness in all of its glories. my b...   \n",
       "2      movement conversation creation contemplation t...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941         my family, my dog, italy, words and music!   \n",
       "59942  iphone contact lenses headphones camera tv rem...   \n",
       "59943  - iphone - friends and family - internet - bay...   \n",
       "59944  music, family, friends, a basketball, hoop, so...   \n",
       "59945  1. family & friends & other humans - interacti...   \n",
       "\n",
       "                                                  essay6  \\\n",
       "0                            duality and humorous things   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                             cats and german philosophy   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941                                   writing my book.   \n",
       "59942  i do most of my thinking on the bus to/from wo...   \n",
       "59943           aside from work, how to improve my home.   \n",
       "59944          what can i do to make someone chuckle....   \n",
       "59945  sex, myself, other people, how amazing everyth...   \n",
       "\n",
       "                                                  essay7  \\\n",
       "0      trying to find someone to hang out with. i am ...   \n",
       "1                                                    NaN   \n",
       "2      viewing. listening. dancing. talking. drinking...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941  running with my dog, finishing up the work wee...   \n",
       "59942      bringin' home bacon, or drinking and shakin'!   \n",
       "59943    out enjoying friendly conversation over dinner.   \n",
       "59944  what i would do on any other day. everydays a ...   \n",
       "59945  out at happy hour with my friends, running int...   \n",
       "\n",
       "                                                  essay8  \\\n",
       "0      i am new to california and looking for someone...   \n",
       "1      i am very open and will share just about anyth...   \n",
       "2      when i was five years old, i was known as \"the...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941  i have a dream to sing at the alconquin in nyc...   \n",
       "59942  when i was 18 i got a tattoo of waldo somewher...   \n",
       "59943               please let me think about this more.   \n",
       "59944  i like walking around in other people's house ...   \n",
       "59945  i wish i could cry like holly hunter in broadc...   \n",
       "\n",
       "                                                  essay9  not_answered_percent  \n",
       "0      you want to be swept off your feet! you are ti...                   0.0  \n",
       "1                                                    NaN                  40.0  \n",
       "2      you are bright, open, intense, silly, ironic, ...                  10.0  \n",
       "3                                  you feel so inclined.                  30.0  \n",
       "4                                                    NaN                  50.0  \n",
       "...                                                  ...                   ...  \n",
       "59941  you are seeking a long term connection of shar...                   0.0  \n",
       "59942     meh if you made it this far you might as well.                   0.0  \n",
       "59943                         we have similar interests.                   0.0  \n",
       "59944              you are interested and interesting...                   0.0  \n",
       "59945  if you have a back-bone, an opinion, a sense o...                   0.0  \n",
       "\n",
       "[59946 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3318fec5",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Replace NaN with empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fa5e570",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "no_nan_df = text_df.replace(np.nan, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "662338bd",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "      <th>not_answered_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay0  essay1  essay2  essay3  essay4  essay5  essay6  essay7  essay8  \\\n",
       "0       False   False   False   False   False   False   False   False   False   \n",
       "1       False   False   False   False   False   False   False   False   False   \n",
       "2       False   False   False   False   False   False   False   False   False   \n",
       "3       False   False   False   False   False   False   False   False   False   \n",
       "4       False   False   False   False   False   False   False   False   False   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59941   False   False   False   False   False   False   False   False   False   \n",
       "59942   False   False   False   False   False   False   False   False   False   \n",
       "59943   False   False   False   False   False   False   False   False   False   \n",
       "59944   False   False   False   False   False   False   False   False   False   \n",
       "59945   False   False   False   False   False   False   False   False   False   \n",
       "\n",
       "       essay9  not_answered_percent  \n",
       "0       False                 False  \n",
       "1       False                 False  \n",
       "2       False                 False  \n",
       "3       False                 False  \n",
       "4       False                 False  \n",
       "...       ...                   ...  \n",
       "59941   False                 False  \n",
       "59942   False                 False  \n",
       "59943   False                 False  \n",
       "59944   False                 False  \n",
       "59945   False                 False  \n",
       "\n",
       "[59946 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_nan_df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b8688",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Combining into one big text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c82998dc",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "no_nan_df['combined'] = no_nan_df.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3cb7bf7",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        about me:  i would love to think that i was so...\n",
       "1        i am a chef: this is what that means. 1. i am ...\n",
       "2        i'm not ashamed of much, but writing public te...\n",
       "3        i work in a library and go to school. . . read...\n",
       "4        hey how's it going? currently vague on the pro...\n",
       "                               ...                        \n",
       "59941    vibrant, expressive, caring optimist. i love b...\n",
       "59942    i'm nick. i never know what to write about mys...\n",
       "59943    hello! i enjoy traveling, watching movies, and...\n",
       "59944    \"all i have in this world are my balls and my ...\n",
       "59945    is it odd that having a little \"enemy\" status ...\n",
       "Name: combined, Length: 59946, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_nan_df.combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482c269",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be12654c",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def basic_cleaning(sentence):\n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() # remove whitespaces\n",
    "    sentence = sentence.lower() # lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) # remove numbers\n",
    "    \n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c66fe1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay0_clean', 'essay1_clean', 'essay2_clean', 'essay3_clean',\n",
       "       'essay4_clean', 'essay5_clean', 'essay6_clean', 'essay7_clean',\n",
       "       'essay8_clean', 'essay9_clean', 'combined_clean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = pd.DataFrame()\n",
    "\n",
    "# Criar Novas colunas essayX_clean\n",
    "essays = no_nan_df.columns[:10]\n",
    "for essay in essays:\n",
    "    cleaned_df[f\"{essay}_clean\"] = no_nan_df[essay].apply(basic_cleaning)\n",
    "\n",
    "cleaned_df['combined_clean'] = no_nan_df.combined.apply(basic_cleaning)\n",
    "\n",
    "cleaned_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ac1e5",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ea73e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507a371",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Let's take one row and play with **Tokenization**, **stopwords** and **lemmatize** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6882aa8a",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>attention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>span</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    essay0_words\n",
       "0          about\n",
       "1             me\n",
       "2              :\n",
       "3              i\n",
       "4          would\n",
       "..           ...\n",
       "264            a\n",
       "265         good\n",
       "266    attention\n",
       "267         span\n",
       "268            .\n",
       "\n",
       "[269 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = no_nan_df.loc[0, 'essay0']\n",
    "\n",
    "word_tokens = word_tokenize(text)\n",
    "\n",
    "pd.DataFrame({'essay0_words': word_tokens})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba46411c",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c98f7df",
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':',\n",
       " 'would',\n",
       " 'love',\n",
       " 'think',\n",
       " 'kind',\n",
       " 'intellectual',\n",
       " ':',\n",
       " 'either',\n",
       " 'dumbest',\n",
       " 'smart',\n",
       " 'guy',\n",
       " ',',\n",
       " 'smartest',\n",
       " 'dumb',\n",
       " 'guy',\n",
       " '.',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'say',\n",
       " 'tell',\n",
       " 'difference',\n",
       " '.',\n",
       " 'love',\n",
       " 'talk',\n",
       " 'ideas',\n",
       " 'concepts',\n",
       " '.',\n",
       " 'forge',\n",
       " 'odd',\n",
       " 'metaphors',\n",
       " 'instead',\n",
       " 'reciting',\n",
       " 'cliches',\n",
       " '.',\n",
       " 'like',\n",
       " 'simularities',\n",
       " 'friend',\n",
       " 'mine',\n",
       " \"'s\",\n",
       " 'house',\n",
       " 'underwater',\n",
       " 'salt',\n",
       " 'mine',\n",
       " '.',\n",
       " 'favorite',\n",
       " 'word',\n",
       " 'salt',\n",
       " 'way',\n",
       " '(',\n",
       " 'weird',\n",
       " 'choice',\n",
       " 'know',\n",
       " ')',\n",
       " '.',\n",
       " 'things',\n",
       " 'life',\n",
       " 'better',\n",
       " 'metaphors',\n",
       " '.',\n",
       " 'seek',\n",
       " 'make',\n",
       " 'little',\n",
       " 'better',\n",
       " 'everyday',\n",
       " ',',\n",
       " 'productively',\n",
       " 'lazy',\n",
       " 'way',\n",
       " '.',\n",
       " 'got',\n",
       " 'tired',\n",
       " 'tying',\n",
       " 'shoes',\n",
       " '.',\n",
       " 'considered',\n",
       " 'hiring',\n",
       " 'five',\n",
       " 'year',\n",
       " 'old',\n",
       " ',',\n",
       " 'would',\n",
       " 'probably',\n",
       " 'tie',\n",
       " 'shoes',\n",
       " '...',\n",
       " 'decided',\n",
       " 'wear',\n",
       " 'leather',\n",
       " 'shoes',\n",
       " 'dress',\n",
       " 'shoes',\n",
       " '.',\n",
       " ':',\n",
       " 'love',\n",
       " 'really',\n",
       " 'serious',\n",
       " ',',\n",
       " 'really',\n",
       " 'deep',\n",
       " 'conversations',\n",
       " 'really',\n",
       " 'silly',\n",
       " 'stuff',\n",
       " '.',\n",
       " 'willing',\n",
       " 'snap',\n",
       " 'light',\n",
       " 'hearted',\n",
       " 'rant',\n",
       " 'kiss',\n",
       " '.',\n",
       " \"n't\",\n",
       " 'funny',\n",
       " ',',\n",
       " 'able',\n",
       " 'make',\n",
       " 'laugh',\n",
       " '.',\n",
       " 'able',\n",
       " 'bend',\n",
       " 'spoons',\n",
       " 'mind',\n",
       " ',',\n",
       " 'telepathically',\n",
       " 'make',\n",
       " 'smile',\n",
       " 'still',\n",
       " 'work',\n",
       " '.',\n",
       " 'love',\n",
       " 'life',\n",
       " ',',\n",
       " 'cool',\n",
       " 'letting',\n",
       " 'wind',\n",
       " 'blow',\n",
       " '.',\n",
       " 'extra',\n",
       " 'points',\n",
       " 'reading',\n",
       " 'guessing',\n",
       " 'favorite',\n",
       " 'video',\n",
       " 'game',\n",
       " '(',\n",
       " 'hints',\n",
       " 'given',\n",
       " 'yet',\n",
       " ')',\n",
       " '.',\n",
       " 'lastly',\n",
       " 'good',\n",
       " 'attention',\n",
       " 'span',\n",
       " '.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "pd.DataFrame()\n",
    "\n",
    "stopwords_removed = [w for w in word_tokens if w in stop_words]\n",
    "\n",
    "tokens_cleaned = [w for w in word_tokens if not w in stop_words]\n",
    "tokens_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba61ac3",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e51b7756",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Lemmatizing the verbs\n",
    "verb_lemmatized = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"v\") # v --> verbs\n",
    "    for word in tokens_cleaned\n",
    "]\n",
    "\n",
    "# 2 - Lemmatizing the nouns\n",
    "noun_lemmatized = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"n\") # n --> nouns\n",
    "    for word in verb_lemmatized\n",
    "]\n",
    "\n",
    "pd.DataFrame(dict(token=tokens_cleaned, verbs=verb_lemmatized, noun=noun_lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711704bc",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6b9e16e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "about me:  i would love to think that i was some some kind of intellectual: either the dumbest smart guy, or the smartest dumb guy. can't say i can tell the difference. i love to talk about ideas and concepts. i forge odd metaphors instead of reciting cliches. like the simularities between a friend of mine's house and an underwater salt mine. my favorite word is salt by the way (weird choice i know). to me most things in life are better as metaphors. i seek to make myself a little better everyday, in some productively lazy way. got tired of tying my shoes. considered hiring a five year old, but would probably have to tie both of our shoes... decided to only wear leather shoes dress shoes.  about you:  you love to have really serious, really deep conversations about really silly stuff. you have to be willing to snap me out of a light hearted rant with a kiss. you don't have to be funny, but you have to be able to make me laugh. you should be able to bend spoons with your mind, and telepathically make me smile while i am still at work. you should love life, and be cool with just letting the wind blow. extra points for reading all this and guessing my favorite video game (no hints given yet). and lastly you have a good attention span.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\": would love think kind intellectual : either dumbest smart guy , smartest dumb guy . ca n't say tell difference . love talk idea concept . forge odd metaphor instead recite cliche . like simularities friend mine 's house underwater salt mine . favorite word salt way ( weird choice know ) . thing life better metaphor . seek make little better everyday , productively lazy way . get tire tie shoe . consider hire five year old , would probably tie shoe ... decide wear leather shoe dress shoe . : love really serious , really deep conversation really silly stuff . will snap light hearted rant kiss . n't funny , able make laugh . able bend spoon mind , telepathically make smile still work . love life , cool let wind blow . extra point read guess favorite video game ( hint give yet ) . lastly good attention span .\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def basic_preprocessing(sentence):\n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize\n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "\n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in stop_words\n",
    "    ]\n",
    "\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\")\n",
    "        for word in tokenized_sentence_cleaned\n",
    "    ]\n",
    "\n",
    "    # 2 - Lemmatizing the nouns\n",
    "    noun_lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"n\")\n",
    "        for word in lemmatized\n",
    "    ]\n",
    "    \n",
    "    cleaned_sentence = ' '.join(word for word in noun_lemmatized)\n",
    "    return cleaned_sentence\n",
    "\n",
    "text = no_nan_df.loc[0, 'essay0']\n",
    "print(f\"Original text:\\n{text}\")\n",
    "basic_preprocessing(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a128df5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        would love think kind intellectual either dumb...\n",
       "1        chef mean workaholic love cook regardless whet...\n",
       "2        im ashamed much write public text online date ...\n",
       "3                                   work library go school\n",
       "4        hey hows go currently vague profile know come ...\n",
       "                               ...                        \n",
       "59941    vibrant expressive care optimist love people t...\n",
       "59942    im nick never know write im sure hand im south...\n",
       "59943    hello enjoy travel watch movie hang friend rul...\n",
       "59944    world ball integrity one take either away momm...\n",
       "59945    odd little enemy status someone make seem inte...\n",
       "Name: essay0_clean, Length: 59946, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.essay0_clean.apply(basic_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb87b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_preprocessed_df = cleaned_df.apply(lambda row: row.apply(basic_preprocessing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71230cbd",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "preprocessed_combined = no_nan_df.combined.apply(basic_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6fa6e4",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "preprocessed_combined.to_frame().rename(columns={'combined': 'combined_preprocess'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016dc420",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "no_nan_df['combined_preprocess'] = preprocessed_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5fee1",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "no_nan_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9035bf0",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c43678",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Using relative frequency rather than count is robust to document length\n",
    "\n",
    "Takes into account the context of the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fe8d6",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Instantiating the TfidfVectorizer\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Training it on the texts\n",
    "weighted_words = pd.DataFrame(tf_idf_vectorizer.fit_transform(no_nan_df.combined_preprocess).toarray(),\n",
    "                 columns = tf_idf_vectorizer.get_feature_names_out())\n",
    "\n",
    "weighted_words"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "319.03px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
