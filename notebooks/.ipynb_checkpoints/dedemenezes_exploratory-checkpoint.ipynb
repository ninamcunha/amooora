{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07016fe-6215-48a0-a685-8c905e4e4357",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# categorical_cols = ['status', 'sex', 'orientation', 'body_type', 'diet', 'drinks', 'drugs',\n",
    "#                     'education', 'ethnicity', 'job', 'location', 'smokes', 'religion', 'sign', 'pets']\n",
    "\n",
    "\n",
    "# label_encoding_cols = ['education', 'ethnicity', 'job', 'location', 'sign']\n",
    "\n",
    "\n",
    "# label_encoders = {}\n",
    "# for col in label_encoding_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     df[col] = le.fit_transform(df[col].astype(str))  # Convert to string to avoid NaN issues\n",
    "#     label_encoders[col] = le  # Save the encoder in case you need to decode later\n",
    "\n",
    "\n",
    "# df = pd.get_dummies(df, columns=[col for col in categorical_cols if col not in label_encoding_cols], drop_first=True)\n",
    "\n",
    "\n",
    "# encoded_file_path = \"okcupid_profiles_encoded.csv\"  # Output file path\n",
    "# df.to_csv(encoded_file_path, index=False)\n",
    "\n",
    "# print(f\"Dataset with encoding saved at: {encoded_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46ba6f-ae1b-40a9-9f26-e89cebc61f93",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Amooora text data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc544f77-1251-4f12-9c31-977561f3774d",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Import libraries and load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cbb7225-da96-41f9-a48d-54545a509f7a",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b46a83-7734-407d-bbd8-365b8fb49cc2",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m..\u001b[0m\r\n",
      "├── \u001b[01;34mnotebooks\u001b[0m\r\n",
      "│   └── dedemenezes_exploratory.ipynb\r\n",
      "├── \u001b[01;34mraw_data\u001b[0m\r\n",
      "│   ├── okcupid_profiles.csv\r\n",
      "│   ├── okcupid_profiles_encoded.csv\r\n",
      "│   ├── \u001b[01;32mparsed_data_public.csv\u001b[0m\r\n",
      "│   ├── \u001b[01;32mquestion_data.csv\u001b[0m\r\n",
      "│   └── \u001b[01;32muser_data_public.csv\u001b[0m\r\n",
      "├── README.md\r\n",
      "└── requirements.txt\r\n",
      "\r\n",
      "2 directories, 8 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae74d9de-6bc2-4cac-8c09-cff9df9b0d24",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/okcupid_profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa890203-d9fd-4a55-8221-fe8b4463ff3e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc076a3a-7275-41c3-b5fb-a44dd59c86af",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  status sex orientation       body_type               diet    drinks  \\\n",
       "0   22  single   m    straight  a little extra  strictly anything  socially   \n",
       "1   35  single   m    straight         average       mostly other     often   \n",
       "\n",
       "       drugs                      education     ethnicity  ...  \\\n",
       "0      never  working on college/university  asian, white  ...   \n",
       "1  sometimes          working on space camp         white  ...   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:  i would love to think that i was so...   \n",
       "1  i am a chef: this is what that means. 1. i am ...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh. ranting about a good salt...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books: absurdistan, the republic, of mice and ...   \n",
       "1  i am die hard christopher moore fan. i don't r...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0                  food. water. cell phone. shelter.   \n",
       "1  delicious porkness in all of its glories. my b...   \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                          NaN   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "1  i am very open and will share just about anyth...   \n",
       "\n",
       "                                              essay9  \n",
       "0  you want to be swept off your feet! you are ti...  \n",
       "1                                                NaN  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4591acf-a7b0-4bb4-8854-9c402893d3ae",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Access Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "210efa5b",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>2012-06-28-14-22</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn't want kids</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>2012-06-27-21-26</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>59</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>sales / marketing / biz dev</td>\n",
       "      <td>2012-06-12-21-47</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>has kids</td>\n",
       "      <td>has dogs</td>\n",
       "      <td>catholicism but not too serious about it</td>\n",
       "      <td>cancer and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white, other</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>entertainment / media</td>\n",
       "      <td>2012-06-29-11-01</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>doesn't have kids</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>leo but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>asian</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>construction / craftsmanship</td>\n",
       "      <td>2012-06-27-23-37</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids</td>\n",
       "      <td>NaN</td>\n",
       "      <td>christianity but not too serious about it</td>\n",
       "      <td>sagittarius but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, black</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>medicine / health</td>\n",
       "      <td>2012-06-23-13-01</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>doesn't have kids, but wants them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>leo and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>trying to quit</td>\n",
       "      <td>english (fluently), spanish (poorly), chinese ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>39</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>gay</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>medicine / health</td>\n",
       "      <td>2012-06-29-00-42</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>catholicism and laughing about it</td>\n",
       "      <td>gemini and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     status sex orientation       body_type               diet  \\\n",
       "0       22     single   m    straight  a little extra  strictly anything   \n",
       "1       35     single   m    straight         average       mostly other   \n",
       "2       38  available   m    straight            thin           anything   \n",
       "3       23     single   m    straight            thin         vegetarian   \n",
       "4       29     single   m    straight        athletic                NaN   \n",
       "...    ...        ...  ..         ...             ...                ...   \n",
       "59941   59     single   f    straight             NaN                NaN   \n",
       "59942   24     single   m    straight             fit    mostly anything   \n",
       "59943   42     single   m    straight         average    mostly anything   \n",
       "59944   27     single   m    straight        athletic    mostly anything   \n",
       "59945   39     single   m         gay         average                NaN   \n",
       "\n",
       "           drinks      drugs                          education  \\\n",
       "0        socially      never      working on college/university   \n",
       "1           often  sometimes              working on space camp   \n",
       "2        socially        NaN     graduated from masters program   \n",
       "3        socially        NaN      working on college/university   \n",
       "4        socially      never  graduated from college/university   \n",
       "...           ...        ...                                ...   \n",
       "59941    socially      never  graduated from college/university   \n",
       "59942       often  sometimes      working on college/university   \n",
       "59943  not at all      never     graduated from masters program   \n",
       "59944    socially      often      working on college/university   \n",
       "59945    socially        NaN     graduated from masters program   \n",
       "\n",
       "                 ethnicity  ...  income                           job  \\\n",
       "0             asian, white  ...      -1                transportation   \n",
       "1                    white  ...   80000          hospitality / travel   \n",
       "2                      NaN  ...      -1                           NaN   \n",
       "3                    white  ...   20000                       student   \n",
       "4      asian, black, other  ...      -1   artistic / musical / writer   \n",
       "...                    ...  ...     ...                           ...   \n",
       "59941                  NaN  ...      -1   sales / marketing / biz dev   \n",
       "59942         white, other  ...      -1         entertainment / media   \n",
       "59943                asian  ...  100000  construction / craftsmanship   \n",
       "59944         asian, black  ...      -1             medicine / health   \n",
       "59945                white  ...      -1             medicine / health   \n",
       "\n",
       "            last_online                         location  \\\n",
       "0      2012-06-28-20-30  south san francisco, california   \n",
       "1      2012-06-29-21-41              oakland, california   \n",
       "2      2012-06-27-09-10        san francisco, california   \n",
       "3      2012-06-28-14-22             berkeley, california   \n",
       "4      2012-06-27-21-26        san francisco, california   \n",
       "...                 ...                              ...   \n",
       "59941  2012-06-12-21-47              oakland, california   \n",
       "59942  2012-06-29-11-01        san francisco, california   \n",
       "59943  2012-06-27-23-37  south san francisco, california   \n",
       "59944  2012-06-23-13-01        san francisco, california   \n",
       "59945  2012-06-29-00-42        san francisco, california   \n",
       "\n",
       "                                    offspring                       pets  \\\n",
       "0      doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "1      doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "2                                         NaN                   has cats   \n",
       "3                           doesn't want kids                 likes cats   \n",
       "4                                         NaN  likes dogs and likes cats   \n",
       "...                                       ...                        ...   \n",
       "59941                                has kids                   has dogs   \n",
       "59942                       doesn't have kids  likes dogs and likes cats   \n",
       "59943                       doesn't have kids                        NaN   \n",
       "59944       doesn't have kids, but wants them  likes dogs and likes cats   \n",
       "59945                                     NaN  likes dogs and likes cats   \n",
       "\n",
       "                                        religion  \\\n",
       "0          agnosticism and very serious about it   \n",
       "1       agnosticism but not too serious about it   \n",
       "2                                            NaN   \n",
       "3                                            NaN   \n",
       "4                                            NaN   \n",
       "...                                          ...   \n",
       "59941   catholicism but not too serious about it   \n",
       "59942                                agnosticism   \n",
       "59943  christianity but not too serious about it   \n",
       "59944   agnosticism but not too serious about it   \n",
       "59945          catholicism and laughing about it   \n",
       "\n",
       "                                           sign          smokes  \\\n",
       "0                                        gemini       sometimes   \n",
       "1                                        cancer              no   \n",
       "2            pisces but it doesn&rsquo;t matter              no   \n",
       "3                                        pisces              no   \n",
       "4                                      aquarius              no   \n",
       "...                                         ...             ...   \n",
       "59941  cancer and it&rsquo;s fun to think about              no   \n",
       "59942           leo but it doesn&rsquo;t matter              no   \n",
       "59943   sagittarius but it doesn&rsquo;t matter              no   \n",
       "59944     leo and it&rsquo;s fun to think about  trying to quit   \n",
       "59945  gemini and it&rsquo;s fun to think about       sometimes   \n",
       "\n",
       "                                                  speaks  \n",
       "0                                                english  \n",
       "1      english (fluently), spanish (poorly), french (...  \n",
       "2                                   english, french, c++  \n",
       "3                               english, german (poorly)  \n",
       "4                                                english  \n",
       "...                                                  ...  \n",
       "59941                                            english  \n",
       "59942                                 english (fluently)  \n",
       "59943                                 english (fluently)  \n",
       "59944  english (fluently), spanish (poorly), chinese ...  \n",
       "59945                                            english  \n",
       "\n",
       "[59946 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, :21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc47a3f-6746-4331-9ec8-b6afe3acef41",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "text_df = df.iloc[:, 21:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd5c95d-0126-4806-ab2f-668c28622044",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>viewing. listening. dancing. talking. drinking...</td>\n",
       "      <td>when i was five years old, i was known as \"the...</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . . lynch, jarmusch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you feel so inclined.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at: http://bagsbrown....</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians at the moment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              essay0  \\\n",
       "0  about me:  i would love to think that i was so...   \n",
       "1  i am a chef: this is what that means. 1. i am ...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh. ranting about a good salt...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at: http://bagsbrown....   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "1                                                NaN   \n",
       "2  my large jaw and large glasses are the physica...   \n",
       "3                  socially awkward but i do my best   \n",
       "4            i smile a lot and my inquisitive nature   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books: absurdistan, the republic, of mice and ...   \n",
       "1  i am die hard christopher moore fan. i don't r...   \n",
       "2  okay this is where the cultural matrix gets so...   \n",
       "3  bataille, celine, beckett. . . lynch, jarmusch...   \n",
       "4  music: bands, rappers, musicians at the moment...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0                  food. water. cell phone. shelter.   \n",
       "1  delicious porkness in all of its glories. my b...   \n",
       "2  movement conversation creation contemplation t...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "3   cats and german philosophy   \n",
       "4                          NaN   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "1                                                NaN   \n",
       "2  viewing. listening. dancing. talking. drinking...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "1  i am very open and will share just about anyth...   \n",
       "2  when i was five years old, i was known as \"the...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay9  \n",
       "0  you want to be swept off your feet! you are ti...  \n",
       "1                                                NaN  \n",
       "2  you are bright, open, intense, silly, ironic, ...  \n",
       "3                              you feel so inclined.  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2440c5-48c0-4ce8-8624-342799de5cab",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Checking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceddae46-534a-4b6a-a1fe-c86b4f7e31d8",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   essay0  54458 non-null  object\n",
      " 1   essay1  52374 non-null  object\n",
      " 2   essay2  50308 non-null  object\n",
      " 3   essay3  48470 non-null  object\n",
      " 4   essay4  49409 non-null  object\n",
      " 5   essay5  49096 non-null  object\n",
      " 6   essay6  46175 non-null  object\n",
      " 7   essay7  47495 non-null  object\n",
      " 8   essay8  40721 non-null  object\n",
      " 9   essay9  47343 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "text_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec7e89-f843-4c95-9467-6260b2d8d474",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298ae729-0ac6-4479-9b34-7115f2d1054e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2134)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a72a264f-f192-4561-8bda-9f2278558166",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59757</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59791</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59857</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59881</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2134 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay0 essay1 essay2 essay3 essay4 essay5 essay6 essay7 essay8 essay9\n",
       "51       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "64       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "80       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "84       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "175      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
       "59757    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "59791    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "59857    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "59881    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "59930    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "\n",
       "[2134 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[text_df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d63151-5d50-44ec-b735-c967e2e259bf",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "We have `2134`duplicated observations all made of empty answers to all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4a646e-3c16-4940-a897-7c09ebcae603",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# no_dup_df = text_df.drop_duplicates()\n",
    "# no_dup_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3de282-1190-4193-86b6-5c08315a59b6",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a2b6ffa-b005-48bd-a2f4-e892bc050dc6",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay8    32.070530\n",
       "essay6    22.972342\n",
       "essay9    21.023922\n",
       "essay7    20.770360\n",
       "essay3    19.143896\n",
       "essay5    18.099623\n",
       "essay4    17.577486\n",
       "essay2    16.077803\n",
       "essay1    12.631368\n",
       "essay0     9.154906\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.isnull().sum().sort_values(ascending=False) / len(text_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30fd8b36-acdd-47a0-b0b4-a8faf7f39f4d",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29866, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19284151",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e0861",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Drop is not an option!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfe4be",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## % of answered questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78726366",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6',\n",
       "       'essay7', 'essay8', 'essay9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a6190a0",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "text_df['not_answered_percent'] = text_df.apply(lambda x: x.isna().sum() / len(text_df.columns) * 100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc66bdad",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "      <th>not_answered_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>viewing. listening. dancing. talking. drinking...</td>\n",
       "      <td>when i was five years old, i was known as \"the...</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, ...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . . lynch, jarmusch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you feel so inclined.</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at: http://bagsbrown....</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians at the moment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>vibrant, expressive, caring optimist. i love b...</td>\n",
       "      <td>the happiest times have been when life came to...</td>\n",
       "      <td>i make an outstanding osso bucco. i am also ve...</td>\n",
       "      <td>i am told that people notice my smile, eyes an...</td>\n",
       "      <td>i am an avid movie watcher and follow the broa...</td>\n",
       "      <td>my family, my dog, italy, words and music!</td>\n",
       "      <td>writing my book.</td>\n",
       "      <td>running with my dog, finishing up the work wee...</td>\n",
       "      <td>i have a dream to sing at the alconquin in nyc...</td>\n",
       "      <td>you are seeking a long term connection of shar...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>i'm nick. i never know what to write about mys...</td>\n",
       "      <td>currently finishing school for film production...</td>\n",
       "      <td>filmmaking, photography, graphic design, web d...</td>\n",
       "      <td>dude, i don't know.</td>\n",
       "      <td>movies: hook (the greatest adventure ever!), g...</td>\n",
       "      <td>iphone contact lenses headphones camera tv rem...</td>\n",
       "      <td>i do most of my thinking on the bus to/from wo...</td>\n",
       "      <td>bringin' home bacon, or drinking and shakin'!</td>\n",
       "      <td>when i was 18 i got a tattoo of waldo somewher...</td>\n",
       "      <td>meh if you made it this far you might as well.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>hello! i enjoy traveling, watching movies, and...</td>\n",
       "      <td>i'm a civil engineer, who enjoys helping the c...</td>\n",
       "      <td>- looking at things objectively - getting thin...</td>\n",
       "      <td>i'm quiet until i get used to the environment ...</td>\n",
       "      <td>last book: \"game change\". movies: bourne serie...</td>\n",
       "      <td>- iphone - friends and family - internet - bay...</td>\n",
       "      <td>aside from work, how to improve my home.</td>\n",
       "      <td>out enjoying friendly conversation over dinner.</td>\n",
       "      <td>please let me think about this more.</td>\n",
       "      <td>we have similar interests.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>\"all i have in this world are my balls and my ...</td>\n",
       "      <td>following my dreams... \"you got a dream... you...</td>\n",
       "      <td>listening</td>\n",
       "      <td>it used to be the hair until i mowed it off bu...</td>\n",
       "      <td>where to begin musically: right now i listen t...</td>\n",
       "      <td>music, family, friends, a basketball, hoop, so...</td>\n",
       "      <td>what can i do to make someone chuckle....</td>\n",
       "      <td>what i would do on any other day. everydays a ...</td>\n",
       "      <td>i like walking around in other people's house ...</td>\n",
       "      <td>you are interested and interesting...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>is it odd that having a little \"enemy\" status ...</td>\n",
       "      <td>i work with elderly people (psychotherapy and ...</td>\n",
       "      <td>i'm a great bullshitter. i don't know what it ...</td>\n",
       "      <td>either that i am funny/sarcastic, or that i am...</td>\n",
       "      <td>i just read the help by kathryn stockett, sooo...</td>\n",
       "      <td>1. family &amp; friends &amp; other humans - interacti...</td>\n",
       "      <td>sex, myself, other people, how amazing everyth...</td>\n",
       "      <td>out at happy hour with my friends, running int...</td>\n",
       "      <td>i wish i could cry like holly hunter in broadc...</td>\n",
       "      <td>if you have a back-bone, an opinion, a sense o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay0  \\\n",
       "0      about me:  i would love to think that i was so...   \n",
       "1      i am a chef: this is what that means. 1. i am ...   \n",
       "2      i'm not ashamed of much, but writing public te...   \n",
       "3              i work in a library and go to school. . .   \n",
       "4      hey how's it going? currently vague on the pro...   \n",
       "...                                                  ...   \n",
       "59941  vibrant, expressive, caring optimist. i love b...   \n",
       "59942  i'm nick. i never know what to write about mys...   \n",
       "59943  hello! i enjoy traveling, watching movies, and...   \n",
       "59944  \"all i have in this world are my balls and my ...   \n",
       "59945  is it odd that having a little \"enemy\" status ...   \n",
       "\n",
       "                                                  essay1  \\\n",
       "0      currently working as an international agent fo...   \n",
       "1      dedicating everyday to being an unbelievable b...   \n",
       "2      i make nerdy software for musicians, artists, ...   \n",
       "3              reading things written by old dead people   \n",
       "4                             work work work work + play   \n",
       "...                                                  ...   \n",
       "59941  the happiest times have been when life came to...   \n",
       "59942  currently finishing school for film production...   \n",
       "59943  i'm a civil engineer, who enjoys helping the c...   \n",
       "59944  following my dreams... \"you got a dream... you...   \n",
       "59945  i work with elderly people (psychotherapy and ...   \n",
       "\n",
       "                                                  essay2  \\\n",
       "0      making people laugh. ranting about a good salt...   \n",
       "1      being silly. having ridiculous amonts of fun w...   \n",
       "2      improvising in different contexts. alternating...   \n",
       "3      playing synthesizers and organizing books acco...   \n",
       "4      creating imagery to look at: http://bagsbrown....   \n",
       "...                                                  ...   \n",
       "59941  i make an outstanding osso bucco. i am also ve...   \n",
       "59942  filmmaking, photography, graphic design, web d...   \n",
       "59943  - looking at things objectively - getting thin...   \n",
       "59944                                          listening   \n",
       "59945  i'm a great bullshitter. i don't know what it ...   \n",
       "\n",
       "                                                  essay3  \\\n",
       "0      the way i look. i am a six foot half asian, ha...   \n",
       "1                                                    NaN   \n",
       "2      my large jaw and large glasses are the physica...   \n",
       "3                      socially awkward but i do my best   \n",
       "4                i smile a lot and my inquisitive nature   \n",
       "...                                                  ...   \n",
       "59941  i am told that people notice my smile, eyes an...   \n",
       "59942                                dude, i don't know.   \n",
       "59943  i'm quiet until i get used to the environment ...   \n",
       "59944  it used to be the hair until i mowed it off bu...   \n",
       "59945  either that i am funny/sarcastic, or that i am...   \n",
       "\n",
       "                                                  essay4  \\\n",
       "0      books: absurdistan, the republic, of mice and ...   \n",
       "1      i am die hard christopher moore fan. i don't r...   \n",
       "2      okay this is where the cultural matrix gets so...   \n",
       "3      bataille, celine, beckett. . . lynch, jarmusch...   \n",
       "4      music: bands, rappers, musicians at the moment...   \n",
       "...                                                  ...   \n",
       "59941  i am an avid movie watcher and follow the broa...   \n",
       "59942  movies: hook (the greatest adventure ever!), g...   \n",
       "59943  last book: \"game change\". movies: bourne serie...   \n",
       "59944  where to begin musically: right now i listen t...   \n",
       "59945  i just read the help by kathryn stockett, sooo...   \n",
       "\n",
       "                                                  essay5  \\\n",
       "0                      food. water. cell phone. shelter.   \n",
       "1      delicious porkness in all of its glories. my b...   \n",
       "2      movement conversation creation contemplation t...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941         my family, my dog, italy, words and music!   \n",
       "59942  iphone contact lenses headphones camera tv rem...   \n",
       "59943  - iphone - friends and family - internet - bay...   \n",
       "59944  music, family, friends, a basketball, hoop, so...   \n",
       "59945  1. family & friends & other humans - interacti...   \n",
       "\n",
       "                                                  essay6  \\\n",
       "0                            duality and humorous things   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                             cats and german philosophy   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941                                   writing my book.   \n",
       "59942  i do most of my thinking on the bus to/from wo...   \n",
       "59943           aside from work, how to improve my home.   \n",
       "59944          what can i do to make someone chuckle....   \n",
       "59945  sex, myself, other people, how amazing everyth...   \n",
       "\n",
       "                                                  essay7  \\\n",
       "0      trying to find someone to hang out with. i am ...   \n",
       "1                                                    NaN   \n",
       "2      viewing. listening. dancing. talking. drinking...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941  running with my dog, finishing up the work wee...   \n",
       "59942      bringin' home bacon, or drinking and shakin'!   \n",
       "59943    out enjoying friendly conversation over dinner.   \n",
       "59944  what i would do on any other day. everydays a ...   \n",
       "59945  out at happy hour with my friends, running int...   \n",
       "\n",
       "                                                  essay8  \\\n",
       "0      i am new to california and looking for someone...   \n",
       "1      i am very open and will share just about anyth...   \n",
       "2      when i was five years old, i was known as \"the...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941  i have a dream to sing at the alconquin in nyc...   \n",
       "59942  when i was 18 i got a tattoo of waldo somewher...   \n",
       "59943               please let me think about this more.   \n",
       "59944  i like walking around in other people's house ...   \n",
       "59945  i wish i could cry like holly hunter in broadc...   \n",
       "\n",
       "                                                  essay9  not_answered_percent  \n",
       "0      you want to be swept off your feet! you are ti...                   0.0  \n",
       "1                                                    NaN                  40.0  \n",
       "2      you are bright, open, intense, silly, ironic, ...                  10.0  \n",
       "3                                  you feel so inclined.                  30.0  \n",
       "4                                                    NaN                  50.0  \n",
       "...                                                  ...                   ...  \n",
       "59941  you are seeking a long term connection of shar...                   0.0  \n",
       "59942     meh if you made it this far you might as well.                   0.0  \n",
       "59943                         we have similar interests.                   0.0  \n",
       "59944              you are interested and interesting...                   0.0  \n",
       "59945  if you have a back-bone, an opinion, a sense o...                   0.0  \n",
       "\n",
       "[59946 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3318fec5",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Replace NaN with empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fa5e570",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "no_nan_df = text_df.replace(np.nan, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "662338bd",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "      <th>not_answered_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay0  essay1  essay2  essay3  essay4  essay5  essay6  essay7  essay8  \\\n",
       "0       False   False   False   False   False   False   False   False   False   \n",
       "1       False   False   False   False   False   False   False   False   False   \n",
       "2       False   False   False   False   False   False   False   False   False   \n",
       "3       False   False   False   False   False   False   False   False   False   \n",
       "4       False   False   False   False   False   False   False   False   False   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59941   False   False   False   False   False   False   False   False   False   \n",
       "59942   False   False   False   False   False   False   False   False   False   \n",
       "59943   False   False   False   False   False   False   False   False   False   \n",
       "59944   False   False   False   False   False   False   False   False   False   \n",
       "59945   False   False   False   False   False   False   False   False   False   \n",
       "\n",
       "       essay9  not_answered_percent  \n",
       "0       False                 False  \n",
       "1       False                 False  \n",
       "2       False                 False  \n",
       "3       False                 False  \n",
       "4       False                 False  \n",
       "...       ...                   ...  \n",
       "59941   False                 False  \n",
       "59942   False                 False  \n",
       "59943   False                 False  \n",
       "59944   False                 False  \n",
       "59945   False                 False  \n",
       "\n",
       "[59946 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_nan_df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b8688",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Combining into one big text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c82998dc",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "no_nan_df['combined'] = no_nan_df.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3cb7bf7",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        about me:  i would love to think that i was so...\n",
       "1        i am a chef: this is what that means. 1. i am ...\n",
       "2        i'm not ashamed of much, but writing public te...\n",
       "3        i work in a library and go to school. . . read...\n",
       "4        hey how's it going? currently vague on the pro...\n",
       "                               ...                        \n",
       "59941    vibrant, expressive, caring optimist. i love b...\n",
       "59942    i'm nick. i never know what to write about mys...\n",
       "59943    hello! i enjoy traveling, watching movies, and...\n",
       "59944    \"all i have in this world are my balls and my ...\n",
       "59945    is it odd that having a little \"enemy\" status ...\n",
       "Name: combined, Length: 59946, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_nan_df.combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482c269",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be12654c",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def basic_cleaning(sentence):\n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() # remove whitespaces\n",
    "    sentence = sentence.lower() # lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) # remove numbers\n",
    "    \n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c66fe1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.DataFrame()\n",
    "\n",
    "# Criar Novas colunas essayX_clean\n",
    "essays = no_nan_df.columns[:10]\n",
    "for essay in essays:\n",
    "    cleaned_df[f\"{essay}_clean\"] = no_nan_df[essay].apply(basic_cleaning)\n",
    "\n",
    "cleaned_df['combined_clean'] = no_nan_df.combined.apply(basic_cleaning)\n",
    "\n",
    "cleaned_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ac1e5",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ea73e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8f65abe",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/dedefla/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507a371",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Let's take one row and play with **Tokenization**, **stopwords** and **lemmatize** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6882aa8a",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "text = no_nan_df.loc[0, 'essay0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a44870c4",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "word_tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72aec40a",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>attention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>span</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    essay0_words\n",
       "0          about\n",
       "1             me\n",
       "2              i\n",
       "3          would\n",
       "4           love\n",
       "..           ...\n",
       "229         have\n",
       "230            a\n",
       "231         good\n",
       "232    attention\n",
       "233         span\n",
       "\n",
       "[234 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'essay0_words': word_tokens})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba46411c",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c98f7df",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2afd4b65",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb7ec8",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrameFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03a76f02",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about',\n",
       " 'me',\n",
       " 'i',\n",
       " 'to',\n",
       " 'that',\n",
       " 'i',\n",
       " 'was',\n",
       " 'some',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'or',\n",
       " 'the',\n",
       " 'i',\n",
       " 'can',\n",
       " 'the',\n",
       " 'i',\n",
       " 'to',\n",
       " 'about',\n",
       " 'and',\n",
       " 'i',\n",
       " 'of',\n",
       " 'the',\n",
       " 'between',\n",
       " 'a',\n",
       " 'of',\n",
       " 'and',\n",
       " 'an',\n",
       " 'my',\n",
       " 'is',\n",
       " 'by',\n",
       " 'the',\n",
       " 'i',\n",
       " 'to',\n",
       " 'me',\n",
       " 'most',\n",
       " 'in',\n",
       " 'are',\n",
       " 'as',\n",
       " 'i',\n",
       " 'to',\n",
       " 'myself',\n",
       " 'a',\n",
       " 'in',\n",
       " 'some',\n",
       " 'of',\n",
       " 'my',\n",
       " 'a',\n",
       " 'but',\n",
       " 'have',\n",
       " 'to',\n",
       " 'both',\n",
       " 'of',\n",
       " 'our',\n",
       " 'to',\n",
       " 'only',\n",
       " 'about',\n",
       " 'you',\n",
       " 'you',\n",
       " 'to',\n",
       " 'have',\n",
       " 'about',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'to',\n",
       " 'me',\n",
       " 'out',\n",
       " 'of',\n",
       " 'a',\n",
       " 'with',\n",
       " 'a',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'but',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'to',\n",
       " 'me',\n",
       " 'you',\n",
       " 'should',\n",
       " 'be',\n",
       " 'to',\n",
       " 'with',\n",
       " 'your',\n",
       " 'and',\n",
       " 'me',\n",
       " 'while',\n",
       " 'i',\n",
       " 'am',\n",
       " 'at',\n",
       " 'you',\n",
       " 'should',\n",
       " 'and',\n",
       " 'be',\n",
       " 'with',\n",
       " 'just',\n",
       " 'the',\n",
       " 'for',\n",
       " 'all',\n",
       " 'this',\n",
       " 'and',\n",
       " 'my',\n",
       " 'no',\n",
       " 'and',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_removed = [w for w in word_tokens if w in stop_words]\n",
    "stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43c82530",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['would',\n",
       " 'love',\n",
       " 'think',\n",
       " 'kind',\n",
       " 'intellectual',\n",
       " 'either',\n",
       " 'dumbest',\n",
       " 'smart',\n",
       " 'guy',\n",
       " 'smartest',\n",
       " 'dumb',\n",
       " 'guy',\n",
       " 'cant',\n",
       " 'say',\n",
       " 'tell',\n",
       " 'difference',\n",
       " 'love',\n",
       " 'talk',\n",
       " 'ideas',\n",
       " 'concepts',\n",
       " 'forge',\n",
       " 'odd',\n",
       " 'metaphors',\n",
       " 'instead',\n",
       " 'reciting',\n",
       " 'cliches',\n",
       " 'like',\n",
       " 'simularities',\n",
       " 'friend',\n",
       " 'mines',\n",
       " 'house',\n",
       " 'underwater',\n",
       " 'salt',\n",
       " 'mine',\n",
       " 'favorite',\n",
       " 'word',\n",
       " 'salt',\n",
       " 'way',\n",
       " 'weird',\n",
       " 'choice',\n",
       " 'know',\n",
       " 'things',\n",
       " 'life',\n",
       " 'better',\n",
       " 'metaphors',\n",
       " 'seek',\n",
       " 'make',\n",
       " 'little',\n",
       " 'better',\n",
       " 'everyday',\n",
       " 'productively',\n",
       " 'lazy',\n",
       " 'way',\n",
       " 'got',\n",
       " 'tired',\n",
       " 'tying',\n",
       " 'shoes',\n",
       " 'considered',\n",
       " 'hiring',\n",
       " 'five',\n",
       " 'year',\n",
       " 'old',\n",
       " 'would',\n",
       " 'probably',\n",
       " 'tie',\n",
       " 'shoes',\n",
       " 'decided',\n",
       " 'wear',\n",
       " 'leather',\n",
       " 'shoes',\n",
       " 'dress',\n",
       " 'shoes',\n",
       " 'love',\n",
       " 'really',\n",
       " 'serious',\n",
       " 'really',\n",
       " 'deep',\n",
       " 'conversations',\n",
       " 'really',\n",
       " 'silly',\n",
       " 'stuff',\n",
       " 'willing',\n",
       " 'snap',\n",
       " 'light',\n",
       " 'hearted',\n",
       " 'rant',\n",
       " 'kiss',\n",
       " 'dont',\n",
       " 'funny',\n",
       " 'able',\n",
       " 'make',\n",
       " 'laugh',\n",
       " 'able',\n",
       " 'bend',\n",
       " 'spoons',\n",
       " 'mind',\n",
       " 'telepathically',\n",
       " 'make',\n",
       " 'smile',\n",
       " 'still',\n",
       " 'work',\n",
       " 'love',\n",
       " 'life',\n",
       " 'cool',\n",
       " 'letting',\n",
       " 'wind',\n",
       " 'blow',\n",
       " 'extra',\n",
       " 'points',\n",
       " 'reading',\n",
       " 'guessing',\n",
       " 'favorite',\n",
       " 'video',\n",
       " 'game',\n",
       " 'hints',\n",
       " 'given',\n",
       " 'yet',\n",
       " 'lastly',\n",
       " 'good',\n",
       " 'attention',\n",
       " 'span']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_cleaned = [w for w in word_tokens if not w in stop_words]\n",
    "tokens_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba61ac3",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e51b7756",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Lemmatizing the verbs\n",
    "verb_lemmatized = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"v\") # v --> verbs\n",
    "    for word in tokens_cleaned\n",
    "]\n",
    "\n",
    "# 2 - Lemmatizing the nouns\n",
    "noun_lemmatized = [\n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"n\") # n --> nouns\n",
    "    for word in verb_lemmatized\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00c85e8e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>verbs</th>\n",
       "      <th>noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think</td>\n",
       "      <td>think</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kind</td>\n",
       "      <td>kind</td>\n",
       "      <td>kind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intellectual</td>\n",
       "      <td>intellectual</td>\n",
       "      <td>intellectual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>yet</td>\n",
       "      <td>yet</td>\n",
       "      <td>yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>lastly</td>\n",
       "      <td>lastly</td>\n",
       "      <td>lastly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>attention</td>\n",
       "      <td>attention</td>\n",
       "      <td>attention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>span</td>\n",
       "      <td>span</td>\n",
       "      <td>span</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            token         verbs          noun\n",
       "0           would         would         would\n",
       "1            love          love          love\n",
       "2           think         think         think\n",
       "3            kind          kind          kind\n",
       "4    intellectual  intellectual  intellectual\n",
       "..            ...           ...           ...\n",
       "116           yet           yet           yet\n",
       "117        lastly        lastly        lastly\n",
       "118          good          good          good\n",
       "119     attention     attention     attention\n",
       "120          span          span          span\n",
       "\n",
       "[121 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dict(token=tokens_cleaned, verbs=verb_lemmatized, noun=noun_lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711704bc",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6b9e16e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     cleaned_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m noun_lemmatized)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_sentence\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtext\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m basic_preprocessing(text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "def basic_preprocessing(sentence):\n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize\n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "\n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in stop_words\n",
    "    ]\n",
    "\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\")\n",
    "        for word in tokenized_sentence_cleaned\n",
    "    ]\n",
    "\n",
    "    # 2 - Lemmatizing the nouns\n",
    "    noun_lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"n\")\n",
    "        for word in lemmatized\n",
    "    ]\n",
    "    \n",
    "    cleaned_sentence = ' '.join(word for word in noun_lemmatized)\n",
    "    return cleaned_sentence\n",
    "\n",
    "print(f\"Original text:\\n{text}\")\n",
    "basic_preprocessing(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a128df5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0_clean</th>\n",
       "      <th>essay1_clean</th>\n",
       "      <th>essay2_clean</th>\n",
       "      <th>essay3_clean</th>\n",
       "      <th>essay4_clean</th>\n",
       "      <th>essay5_clean</th>\n",
       "      <th>essay6_clean</th>\n",
       "      <th>essay7_clean</th>\n",
       "      <th>essay8_clean</th>\n",
       "      <th>essay9_clean</th>\n",
       "      <th>combined_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about me  i would love to think that i was som...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh ranting about a good salti...</td>\n",
       "      <td>the way i look i am a six foot half asian half...</td>\n",
       "      <td>books absurdistan the republic of mice and men...</td>\n",
       "      <td>food water cell phone shelter</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with i am d...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet you are tir...</td>\n",
       "      <td>about me  i would love to think that i was som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am a chef this is what that means  i am a wo...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly having ridiculous amonts of fun wh...</td>\n",
       "      <td></td>\n",
       "      <td>i am die hard christopher moore fan i dont rea...</td>\n",
       "      <td>delicious porkness in all of its glories my bi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>i am very open and will share just about anything</td>\n",
       "      <td></td>\n",
       "      <td>i am a chef this is what that means  i am a wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im not ashamed of much but writing public text...</td>\n",
       "      <td>i make nerdy software for musicians artists an...</td>\n",
       "      <td>improvising in different contexts alternating ...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td></td>\n",
       "      <td>viewing listening dancing talking drinking per...</td>\n",
       "      <td>when i was five years old i was known as the b...</td>\n",
       "      <td>you are bright open intense silly ironic criti...</td>\n",
       "      <td>im not ashamed of much but writing public text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i work in a library and go to school</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille celine beckett   lynch jarmusch rw fa...</td>\n",
       "      <td></td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>you feel so inclined</td>\n",
       "      <td>i work in a library and go to school   reading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey hows it going currently vague on the profi...</td>\n",
       "      <td>work work work work  play</td>\n",
       "      <td>creating imagery to look at httpbagsbrownblogs...</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music bands rappers musicians at the moment th...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hey hows it going currently vague on the profi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>vibrant expressive caring optimist i love bein...</td>\n",
       "      <td>the happiest times have been when life came to...</td>\n",
       "      <td>i make an outstanding osso bucco i am also ver...</td>\n",
       "      <td>i am told that people notice my smile eyes and...</td>\n",
       "      <td>i am an avid movie watcher and follow the broa...</td>\n",
       "      <td>my family my dog italy words and music</td>\n",
       "      <td>writing my book</td>\n",
       "      <td>running with my dog finishing up the work week...</td>\n",
       "      <td>i have a dream to sing at the alconquin in nyc...</td>\n",
       "      <td>you are seeking a long term connection of shar...</td>\n",
       "      <td>vibrant expressive caring optimist i love bein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>im nick i never know what to write about mysel...</td>\n",
       "      <td>currently finishing school for film production...</td>\n",
       "      <td>filmmaking photography graphic design web desi...</td>\n",
       "      <td>dude i dont know</td>\n",
       "      <td>movies hook the greatest adventure ever gladia...</td>\n",
       "      <td>iphone contact lenses headphones camera tv rem...</td>\n",
       "      <td>i do most of my thinking on the bus tofrom wor...</td>\n",
       "      <td>bringin home bacon or drinking and shakin</td>\n",
       "      <td>when i was  i got a tattoo of waldo somewhere ...</td>\n",
       "      <td>meh if you made it this far you might as well</td>\n",
       "      <td>im nick i never know what to write about mysel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>hello i enjoy traveling watching movies and ha...</td>\n",
       "      <td>im a civil engineer who enjoys helping the cit...</td>\n",
       "      <td>looking at things objectively  getting things...</td>\n",
       "      <td>im quiet until i get used to the environment b...</td>\n",
       "      <td>last book game change movies bourne series act...</td>\n",
       "      <td>iphone  friends and family  internet  bay are...</td>\n",
       "      <td>aside from work how to improve my home</td>\n",
       "      <td>out enjoying friendly conversation over dinner</td>\n",
       "      <td>please let me think about this more</td>\n",
       "      <td>we have similar interests</td>\n",
       "      <td>hello i enjoy traveling watching movies and ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>all i have in this world are my balls and my i...</td>\n",
       "      <td>following my dreams you got a dream you gotta ...</td>\n",
       "      <td>listening</td>\n",
       "      <td>it used to be the hair until i mowed it off bu...</td>\n",
       "      <td>where to begin musically right now i listen to...</td>\n",
       "      <td>music family friends a basketball hoop somethi...</td>\n",
       "      <td>what can i do to make someone chuckle</td>\n",
       "      <td>what i would do on any other day everydays a f...</td>\n",
       "      <td>i like walking around in other peoples house n...</td>\n",
       "      <td>you are interested and interesting</td>\n",
       "      <td>all i have in this world are my balls and my i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>is it odd that having a little enemy status wi...</td>\n",
       "      <td>i work with elderly people psychotherapy and c...</td>\n",
       "      <td>im a great bullshitter i dont know what it is ...</td>\n",
       "      <td>either that i am funnysarcastic or that i am t...</td>\n",
       "      <td>i just read the help by kathryn stockett soooo...</td>\n",
       "      <td>family  friends  other humans  interaction  m...</td>\n",
       "      <td>sex myself other people how amazing everything...</td>\n",
       "      <td>out at happy hour with my friends running into...</td>\n",
       "      <td>i wish i could cry like holly hunter in broadc...</td>\n",
       "      <td>if you have a backbone an opinion a sense of h...</td>\n",
       "      <td>is it odd that having a little enemy status wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            essay0_clean  \\\n",
       "0      about me  i would love to think that i was som...   \n",
       "1      i am a chef this is what that means  i am a wo...   \n",
       "2      im not ashamed of much but writing public text...   \n",
       "3                 i work in a library and go to school     \n",
       "4      hey hows it going currently vague on the profi...   \n",
       "...                                                  ...   \n",
       "59941  vibrant expressive caring optimist i love bein...   \n",
       "59942  im nick i never know what to write about mysel...   \n",
       "59943  hello i enjoy traveling watching movies and ha...   \n",
       "59944  all i have in this world are my balls and my i...   \n",
       "59945  is it odd that having a little enemy status wi...   \n",
       "\n",
       "                                            essay1_clean  \\\n",
       "0      currently working as an international agent fo...   \n",
       "1      dedicating everyday to being an unbelievable b...   \n",
       "2      i make nerdy software for musicians artists an...   \n",
       "3              reading things written by old dead people   \n",
       "4                              work work work work  play   \n",
       "...                                                  ...   \n",
       "59941  the happiest times have been when life came to...   \n",
       "59942  currently finishing school for film production...   \n",
       "59943  im a civil engineer who enjoys helping the cit...   \n",
       "59944  following my dreams you got a dream you gotta ...   \n",
       "59945  i work with elderly people psychotherapy and c...   \n",
       "\n",
       "                                            essay2_clean  \\\n",
       "0      making people laugh ranting about a good salti...   \n",
       "1      being silly having ridiculous amonts of fun wh...   \n",
       "2      improvising in different contexts alternating ...   \n",
       "3      playing synthesizers and organizing books acco...   \n",
       "4      creating imagery to look at httpbagsbrownblogs...   \n",
       "...                                                  ...   \n",
       "59941  i make an outstanding osso bucco i am also ver...   \n",
       "59942  filmmaking photography graphic design web desi...   \n",
       "59943   looking at things objectively  getting things...   \n",
       "59944                                          listening   \n",
       "59945  im a great bullshitter i dont know what it is ...   \n",
       "\n",
       "                                            essay3_clean  \\\n",
       "0      the way i look i am a six foot half asian half...   \n",
       "1                                                          \n",
       "2      my large jaw and large glasses are the physica...   \n",
       "3                      socially awkward but i do my best   \n",
       "4                i smile a lot and my inquisitive nature   \n",
       "...                                                  ...   \n",
       "59941  i am told that people notice my smile eyes and...   \n",
       "59942                                   dude i dont know   \n",
       "59943  im quiet until i get used to the environment b...   \n",
       "59944  it used to be the hair until i mowed it off bu...   \n",
       "59945  either that i am funnysarcastic or that i am t...   \n",
       "\n",
       "                                            essay4_clean  \\\n",
       "0      books absurdistan the republic of mice and men...   \n",
       "1      i am die hard christopher moore fan i dont rea...   \n",
       "2      okay this is where the cultural matrix gets so...   \n",
       "3      bataille celine beckett   lynch jarmusch rw fa...   \n",
       "4      music bands rappers musicians at the moment th...   \n",
       "...                                                  ...   \n",
       "59941  i am an avid movie watcher and follow the broa...   \n",
       "59942  movies hook the greatest adventure ever gladia...   \n",
       "59943  last book game change movies bourne series act...   \n",
       "59944  where to begin musically right now i listen to...   \n",
       "59945  i just read the help by kathryn stockett soooo...   \n",
       "\n",
       "                                            essay5_clean  \\\n",
       "0                          food water cell phone shelter   \n",
       "1      delicious porkness in all of its glories my bi...   \n",
       "2      movement conversation creation contemplation t...   \n",
       "3                                                          \n",
       "4                                                          \n",
       "...                                                  ...   \n",
       "59941             my family my dog italy words and music   \n",
       "59942  iphone contact lenses headphones camera tv rem...   \n",
       "59943   iphone  friends and family  internet  bay are...   \n",
       "59944  music family friends a basketball hoop somethi...   \n",
       "59945   family  friends  other humans  interaction  m...   \n",
       "\n",
       "                                            essay6_clean  \\\n",
       "0                            duality and humorous things   \n",
       "1                                                          \n",
       "2                                                          \n",
       "3                             cats and german philosophy   \n",
       "4                                                          \n",
       "...                                                  ...   \n",
       "59941                                    writing my book   \n",
       "59942  i do most of my thinking on the bus tofrom wor...   \n",
       "59943             aside from work how to improve my home   \n",
       "59944              what can i do to make someone chuckle   \n",
       "59945  sex myself other people how amazing everything...   \n",
       "\n",
       "                                            essay7_clean  \\\n",
       "0      trying to find someone to hang out with i am d...   \n",
       "1                                                          \n",
       "2      viewing listening dancing talking drinking per...   \n",
       "3                                                          \n",
       "4                                                          \n",
       "...                                                  ...   \n",
       "59941  running with my dog finishing up the work week...   \n",
       "59942          bringin home bacon or drinking and shakin   \n",
       "59943     out enjoying friendly conversation over dinner   \n",
       "59944  what i would do on any other day everydays a f...   \n",
       "59945  out at happy hour with my friends running into...   \n",
       "\n",
       "                                            essay8_clean  \\\n",
       "0      i am new to california and looking for someone...   \n",
       "1      i am very open and will share just about anything   \n",
       "2      when i was five years old i was known as the b...   \n",
       "3                                                          \n",
       "4                                                          \n",
       "...                                                  ...   \n",
       "59941  i have a dream to sing at the alconquin in nyc...   \n",
       "59942  when i was  i got a tattoo of waldo somewhere ...   \n",
       "59943                please let me think about this more   \n",
       "59944  i like walking around in other peoples house n...   \n",
       "59945  i wish i could cry like holly hunter in broadc...   \n",
       "\n",
       "                                            essay9_clean  \\\n",
       "0      you want to be swept off your feet you are tir...   \n",
       "1                                                          \n",
       "2      you are bright open intense silly ironic criti...   \n",
       "3                                   you feel so inclined   \n",
       "4                                                          \n",
       "...                                                  ...   \n",
       "59941  you are seeking a long term connection of shar...   \n",
       "59942      meh if you made it this far you might as well   \n",
       "59943                          we have similar interests   \n",
       "59944                 you are interested and interesting   \n",
       "59945  if you have a backbone an opinion a sense of h...   \n",
       "\n",
       "                                          combined_clean  \n",
       "0      about me  i would love to think that i was som...  \n",
       "1      i am a chef this is what that means  i am a wo...  \n",
       "2      im not ashamed of much but writing public text...  \n",
       "3      i work in a library and go to school   reading...  \n",
       "4      hey hows it going currently vague on the profi...  \n",
       "...                                                  ...  \n",
       "59941  vibrant expressive caring optimist i love bein...  \n",
       "59942  im nick i never know what to write about mysel...  \n",
       "59943  hello i enjoy traveling watching movies and ha...  \n",
       "59944  all i have in this world are my balls and my i...  \n",
       "59945  is it odd that having a little enemy status wi...  \n",
       "\n",
       "[59946 rows x 11 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.essay0_clean.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71230cbd",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "preprocessed_combined = no_nan_df.combined.apply(basic_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce6fa6e4",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>would love think kind intellectual either dumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chef mean workaholic love cook regardless whet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im ashamed much write public text online date ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>work library go school read thing write old de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey hows go currently vague profile know come ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>vibrant expressive care optimist love people t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>im nick never know write im sure hand im south...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>hello enjoy travel watch movie hang friend rul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>world ball integrity one take either away momm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>odd little enemy status someone make seem inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     combined_preprocess\n",
       "0      would love think kind intellectual either dumb...\n",
       "1      chef mean workaholic love cook regardless whet...\n",
       "2      im ashamed much write public text online date ...\n",
       "3      work library go school read thing write old de...\n",
       "4      hey hows go currently vague profile know come ...\n",
       "...                                                  ...\n",
       "59941  vibrant expressive care optimist love people t...\n",
       "59942  im nick never know write im sure hand im south...\n",
       "59943  hello enjoy travel watch movie hang friend rul...\n",
       "59944  world ball integrity one take either away momm...\n",
       "59945  odd little enemy status someone make seem inte...\n",
       "\n",
       "[59946 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_combined.to_frame().rename(columns={'combined': 'combined_preprocess'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "016dc420",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "no_nan_df['combined_preprocess'] = preprocessed_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53e5fee1",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "      <th>not_answered_percent</th>\n",
       "      <th>combined</th>\n",
       "      <th>combined_preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about me  i would love to think that i was som...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>about me  i would love to think that i was som...</td>\n",
       "      <td>would love think kind intellectual either dumb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              essay0  \\\n",
       "0  about me  i would love to think that i was som...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh. ranting about a good salt...   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books: absurdistan, the republic, of mice and ...   \n",
       "\n",
       "                              essay5                       essay6  \\\n",
       "0  food. water. cell phone. shelter.  duality and humorous things   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "\n",
       "                                              essay9  not_answered_percent  \\\n",
       "0  you want to be swept off your feet! you are ti...                   0.0   \n",
       "\n",
       "                                            combined  \\\n",
       "0  about me  i would love to think that i was som...   \n",
       "\n",
       "                                 combined_preprocess  \n",
       "0  would love think kind intellectual either dumb...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_nan_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9035bf0",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c43678",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Using relative frequency rather than count is robust to document length\n",
    "\n",
    "Takes into account the context of the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea5fe8d6",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 104. GiB for an array with shape (59946, 231992) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m tf_idf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Training it on the texts\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m weighted_words \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mtf_idf_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_nan_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombined_preprocess\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      6\u001b[0m                  columns \u001b[38;5;241m=\u001b[39m tf_idf_vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n\u001b[1;32m      8\u001b[0m weighted_words\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/amooora/lib/python3.10/site-packages/scipy/sparse/_compressed.py:1170\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1170\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/amooora/lib/python3.10/site-packages/scipy/sparse/_base.py:1367\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 104. GiB for an array with shape (59946, 231992) and data type float64"
     ]
    }
   ],
   "source": [
    "# Instantiating the TfidfVectorizer\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Training it on the texts\n",
    "weighted_words = pd.DataFrame(tf_idf_vectorizer.fit_transform(no_nan_df.combined_preprocess).toarray(),\n",
    "                 columns = tf_idf_vectorizer.get_feature_names_out())\n",
    "\n",
    "weighted_words"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "319.03px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
