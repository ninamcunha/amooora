{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a71ba6f-540c-4562-8374-5f929c26381d",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590b694-91b6-4943-8830-3f2e7f916d28",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b071fb3-d79a-4fb4-93a3-ee85d088a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "import implicit\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb063a5c-f80c-4bed-9384-3cb3f27addfc",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866ee86a-1b73-4c97-abbb-7fbe392d6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok=pd.read_csv('../raw_data/ok_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3c62e3-bb2f-4fbf-a2b5-33a0be243b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.read_csv('../raw_data/text_and_topics.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30dcd77-c7a7-4a04-a20d-7af05e710f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = pd.concat([ok, topics], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dd80b9-7e5e-45b9-8369-0b44ff7e3830",
   "metadata": {},
   "source": [
    "## Defining X vector with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "460bbe3d-6062-479c-beed-3772c1e6dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cat=ok.iloc[:,1:107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "729fcb48-1c6b-42b3-96d5-b86000c34e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=ok.iloc[:,116:121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a136765-1dbc-484c-a038-0f802171900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat([num_cat, text], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f05aa3-02ae-4b6b-8ca1-31b6d7feeb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 20  # Get more matches to filter by gender & orientation\n",
    "\n",
    "# Fit KNN model\n",
    "knn = NearestNeighbors(n_neighbors=n_neighbors, metric='euclidean')\n",
    "knn.fit(x)\n",
    "\n",
    "# Get the nearest neighbors (including self)\n",
    "distances, indices = knn.kneighbors(x)\n",
    "\n",
    "# Function to filter based on orientation & gender\n",
    "def get_valid_matches(idx):\n",
    "    user_gender = ok.loc[idx, 'female']  # 1 = Female, 0 = Male\n",
    "    is_bisexual = ok.loc[idx, 'orientation_bisexual'] == 1\n",
    "    is_gay = ok.loc[idx, 'orientation_gay'] == 1\n",
    "    is_straight = ok.loc[idx, 'orientation_straight'] == 1\n",
    "\n",
    "    valid_matches = []\n",
    "    count = 0\n",
    "\n",
    "    for neighbor_idx, dist in zip(indices[idx, 1:], distances[idx, 1:]):  # Exclude self\n",
    "        neighbor_gender = ok.loc[neighbor_idx, 'female']\n",
    "\n",
    "        # Matching logic\n",
    "        if is_bisexual or (is_straight and user_gender != neighbor_gender) or (is_gay and user_gender == neighbor_gender):\n",
    "            valid_matches.append((neighbor_idx, dist))\n",
    "            count += 1\n",
    "            if count == 5:  # Stop after 5 valid matches\n",
    "                break\n",
    "    \n",
    "    return valid_matches\n",
    "\n",
    "# Apply filtering for all users\n",
    "match_indices = []\n",
    "match_distances = []\n",
    "\n",
    "for idx in range(len(ok)):\n",
    "    matches = get_valid_matches(idx)\n",
    "    \n",
    "    # If not enough matches, fill with NaN\n",
    "    while len(matches) < 5:\n",
    "        matches.append((None, None))\n",
    "\n",
    "    match_indices.append([m[0] for m in matches])\n",
    "    match_distances.append([m[1] for m in matches])\n",
    "\n",
    "# Save matches to the dataset\n",
    "for i in range(5):\n",
    "    ok[f'match_{i+1}_index'] = [row[i] for row in match_indices]\n",
    "    ok[f'match_{i+1}_distance'] = [row[i] for row in match_distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32951572-c2f7-4009-b157-b2c9345d9b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_scaled</th>\n",
       "      <th>single</th>\n",
       "      <th>female</th>\n",
       "      <th>orientation_bisexual</th>\n",
       "      <th>orientation_gay</th>\n",
       "      <th>orientation_straight</th>\n",
       "      <th>body_type_athletic</th>\n",
       "      <th>body_type_average</th>\n",
       "      <th>body_type_curvy</th>\n",
       "      <th>body_type_fit</th>\n",
       "      <th>...</th>\n",
       "      <th>match_1_index</th>\n",
       "      <th>match_1_distance</th>\n",
       "      <th>match_2_index</th>\n",
       "      <th>match_2_distance</th>\n",
       "      <th>match_3_index</th>\n",
       "      <th>match_3_distance</th>\n",
       "      <th>match_4_index</th>\n",
       "      <th>match_4_distance</th>\n",
       "      <th>match_5_index</th>\n",
       "      <th>match_5_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.078431</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>51038.0</td>\n",
       "      <td>3.811792</td>\n",
       "      <td>11098.0</td>\n",
       "      <td>3.918768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>55336.0</td>\n",
       "      <td>3.679834</td>\n",
       "      <td>46448.0</td>\n",
       "      <td>3.905600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.392157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12169.0</td>\n",
       "      <td>3.769973</td>\n",
       "      <td>31921.0</td>\n",
       "      <td>3.792117</td>\n",
       "      <td>30799.0</td>\n",
       "      <td>3.907568</td>\n",
       "      <td>38045.0</td>\n",
       "      <td>3.919192</td>\n",
       "      <td>56791.0</td>\n",
       "      <td>3.948018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.098039</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52475.0</td>\n",
       "      <td>3.240542</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>3.475727</td>\n",
       "      <td>34137.0</td>\n",
       "      <td>3.653172</td>\n",
       "      <td>53227.0</td>\n",
       "      <td>3.663476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.215686</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36386.0</td>\n",
       "      <td>3.106583</td>\n",
       "      <td>34667.0</td>\n",
       "      <td>3.271129</td>\n",
       "      <td>32466.0</td>\n",
       "      <td>3.298720</td>\n",
       "      <td>44081.0</td>\n",
       "      <td>3.375794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>0.803922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>50126.0</td>\n",
       "      <td>3.353490</td>\n",
       "      <td>48181.0</td>\n",
       "      <td>3.401199</td>\n",
       "      <td>36020.0</td>\n",
       "      <td>3.477639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>59896.0</td>\n",
       "      <td>3.467010</td>\n",
       "      <td>52117.0</td>\n",
       "      <td>3.613204</td>\n",
       "      <td>16296.0</td>\n",
       "      <td>3.614896</td>\n",
       "      <td>46448.0</td>\n",
       "      <td>3.618499</td>\n",
       "      <td>59387.0</td>\n",
       "      <td>3.621909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49716.0</td>\n",
       "      <td>3.409213</td>\n",
       "      <td>51574.0</td>\n",
       "      <td>3.487132</td>\n",
       "      <td>18765.0</td>\n",
       "      <td>3.546465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17656.0</td>\n",
       "      <td>3.733573</td>\n",
       "      <td>47273.0</td>\n",
       "      <td>3.823109</td>\n",
       "      <td>27294.0</td>\n",
       "      <td>3.825668</td>\n",
       "      <td>11418.0</td>\n",
       "      <td>3.831555</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>3.844830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38229.0</td>\n",
       "      <td>3.101404</td>\n",
       "      <td>54383.0</td>\n",
       "      <td>3.163504</td>\n",
       "      <td>9725.0</td>\n",
       "      <td>3.253668</td>\n",
       "      <td>13482.0</td>\n",
       "      <td>3.372361</td>\n",
       "      <td>45837.0</td>\n",
       "      <td>3.402994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_scaled  single  female  orientation_bisexual  orientation_gay  \\\n",
       "0        0.078431       1       0                     0                0   \n",
       "1        0.333333       1       0                     0                0   \n",
       "2        0.392157       0       0                     0                0   \n",
       "3        0.098039       1       0                     0                0   \n",
       "4        0.215686       1       0                     0                0   \n",
       "...           ...     ...     ...                   ...              ...   \n",
       "59941    0.803922       1       1                     0                0   \n",
       "59942    0.117647       1       0                     0                0   \n",
       "59943    0.470588       1       0                     0                0   \n",
       "59944    0.176471       1       0                     0                0   \n",
       "59945    0.411765       1       0                     0                1   \n",
       "\n",
       "       orientation_straight  body_type_athletic  body_type_average  \\\n",
       "0                         1                   0                  0   \n",
       "1                         1                   0                  1   \n",
       "2                         1                   0                  0   \n",
       "3                         1                   0                  0   \n",
       "4                         1                   1                  0   \n",
       "...                     ...                 ...                ...   \n",
       "59941                     1                   0                  0   \n",
       "59942                     1                   0                  0   \n",
       "59943                     1                   0                  1   \n",
       "59944                     1                   1                  0   \n",
       "59945                     0                   0                  1   \n",
       "\n",
       "       body_type_curvy  body_type_fit  ...  match_1_index  match_1_distance  \\\n",
       "0                    0              0  ...        51038.0          3.811792   \n",
       "1                    0              0  ...        55336.0          3.679834   \n",
       "2                    0              0  ...        12169.0          3.769973   \n",
       "3                    0              0  ...        52475.0          3.240542   \n",
       "4                    0              0  ...        36386.0          3.106583   \n",
       "...                ...            ...  ...            ...               ...   \n",
       "59941                0              0  ...        50126.0          3.353490   \n",
       "59942                0              1  ...        59896.0          3.467010   \n",
       "59943                0              0  ...        49716.0          3.409213   \n",
       "59944                0              0  ...        17656.0          3.733573   \n",
       "59945                0              0  ...        38229.0          3.101404   \n",
       "\n",
       "       match_2_index  match_2_distance  match_3_index  match_3_distance  \\\n",
       "0            11098.0          3.918768            NaN               NaN   \n",
       "1            46448.0          3.905600            NaN               NaN   \n",
       "2            31921.0          3.792117        30799.0          3.907568   \n",
       "3             1712.0          3.475727        34137.0          3.653172   \n",
       "4            34667.0          3.271129        32466.0          3.298720   \n",
       "...              ...               ...            ...               ...   \n",
       "59941        48181.0          3.401199        36020.0          3.477639   \n",
       "59942        52117.0          3.613204        16296.0          3.614896   \n",
       "59943        51574.0          3.487132        18765.0          3.546465   \n",
       "59944        47273.0          3.823109        27294.0          3.825668   \n",
       "59945        54383.0          3.163504         9725.0          3.253668   \n",
       "\n",
       "       match_4_index  match_4_distance  match_5_index  match_5_distance  \n",
       "0                NaN               NaN            NaN               NaN  \n",
       "1                NaN               NaN            NaN               NaN  \n",
       "2            38045.0          3.919192        56791.0          3.948018  \n",
       "3            53227.0          3.663476            NaN               NaN  \n",
       "4            44081.0          3.375794            NaN               NaN  \n",
       "...              ...               ...            ...               ...  \n",
       "59941            NaN               NaN            NaN               NaN  \n",
       "59942        46448.0          3.618499        59387.0          3.621909  \n",
       "59943            NaN               NaN            NaN               NaN  \n",
       "59944        11418.0          3.831555         3913.0          3.844830  \n",
       "59945        13482.0          3.372361        45837.0          3.402994  \n",
       "\n",
       "[59946 rows x 134 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa54528a-5c81-463a-955d-11b26f8c4356",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Function to run several KNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2579fc-9760-4939-a034-068445cb6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_and_evaluate(dataset=ok, X=None, n_neighbors=10):\n",
    "    \"\"\"\n",
    "    Runs a KNN model and calculates evaluation metrics, including average match distance\n",
    "    and clustering metrics based on pseudo-clusters.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: DataFrame, the dataset to use (default is 'ok')\n",
    "    - X: DataFrame, the feature vector\n",
    "    - n_neighbors: int, number of similar individuals to return per person (default=10)\n",
    "    \n",
    "    Returns:\n",
    "    - Updated DataFrame with the most similar individuals per person\n",
    "    - Prints model evaluation metrics\n",
    "    \"\"\"\n",
    "    if X is None:\n",
    "        raise ValueError(\"Feature vector X must be provided\")\n",
    "    \n",
    "    # Fit KNN model\n",
    "    knn = NearestNeighbors(n_neighbors=n_neighbors + 1, metric='euclidean')\n",
    "    knn.fit(X)  # Fit on the feature vectors\n",
    "    \n",
    "    # Find the nearest neighbors\n",
    "    distances, indices = knn.kneighbors(X)\n",
    "    \n",
    "    # Create a dictionary to store the most similar people for each individual\n",
    "    similar_people = {}\n",
    "    avg_match_distances = []\n",
    "    \n",
    "    for i, index in enumerate(dataset.index):\n",
    "        # Exclude self (index 0), as it's included in the nearest neighbors\n",
    "        similar_people[index] = indices[i][1:].tolist()  # Exclude the person itself\n",
    "        \n",
    "        # Compute average match distance for each person\n",
    "        avg_distance = np.mean(distances[i][1:])  # Exclude self\n",
    "        avg_match_distances.append(avg_distance)\n",
    "    \n",
    "    # Compute overall Average Match Distance (AMD)\n",
    "    overall_avg_match_distance = np.mean(avg_match_distances)\n",
    "    print(f\"Average Match Distance (AMD): {overall_avg_match_distance:.4f}\")\n",
    "    \n",
    "    # Convert the dictionary into a DataFrame\n",
    "    similar_df = pd.DataFrame.from_dict(similar_people, orient='index')\n",
    "    similar_df.columns = [f'similar_{i+1}' for i in range(n_neighbors)]\n",
    "    \n",
    "    # Merge with the original dataset\n",
    "    dataset = dataset.merge(similar_df, left_index=True, right_index=True)\n",
    "    \n",
    "    # Use the nearest neighbor indices to create pseudo-clusters\n",
    "    pseudo_clusters = indices[:, 0]  # Use the nearest neighbor as the pseudo-cluster label\n",
    "    \n",
    "    # Compute clustering metrics\n",
    "    silhouette_avg = silhouette_score(X, pseudo_clusters)\n",
    "    davies_bouldin = davies_bouldin_score(X, pseudo_clusters)\n",
    "    calinski_harabasz = calinski_harabasz_score(X, pseudo_clusters)\n",
    "    \n",
    "    print(f\"Silhouette Score: {silhouette_avg:.4f}\")\n",
    "    print(f\"Davies-Bouldin Score: {davies_bouldin:.4f}\")\n",
    "    print(f\"Calinski-Harabasz Score: {calinski_harabasz:.4f}\")\n",
    "    \n",
    "    # Return updated dataset and evaluation metrics\n",
    "    metrics = {\n",
    "        'Silhouette Score': silhouette_avg,\n",
    "        'Davies-Bouldin Score': davies_bouldin,\n",
    "        'Calinski-Harabasz Score': calinski_harabasz,\n",
    "        'Average Match Distance': overall_avg_match_distance\n",
    "    }\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236b7e4-af78-4216-9577-b62b42c06732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Match Distance (AMD): 2.9985\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_and_evaluate(dataset=ok, X=x, n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f61d4-0a15-4b9d-b136-a9be94d1bb17",
   "metadata": {},
   "source": [
    "### Model 1: Baseline 5 LDA Topics, all 111 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "675100de-9680-47fd-960a-f6a57f229d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Silhouette Score': 0.020581739133098898,\n",
       " 'Davies-Bouldin Index': 3.6779848197346308,\n",
       " 'Calinski-Harabasz Score': 688.5955142538597,\n",
       " 'Average Match Distance': 3.245550940371514,\n",
       " 'Gender/Orientation Match Accuracy': 1.0}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_knn_and_evaluate(20, x, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd97a5b7-71ba-4951-abb2-87bca1199e38",
   "metadata": {},
   "source": [
    "### Model 2: 2 LDA Topics, all 111 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "185f7504-78dd-4ecc-b4b3-cf43acd43ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=ok.iloc[:,121:123]\n",
    "num_cat=ok.iloc[:,1:107]\n",
    "x = pd.concat([num_cat, text], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ed4d69f-393f-4d39-9e5b-7f88325776ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Silhouette Score': 0.020845198435285095,\n",
       " 'Davies-Bouldin Index': 3.6294405236603535,\n",
       " 'Calinski-Harabasz Score': 696.1035073024036,\n",
       " 'Average Match Distance': 3.1157450996331484,\n",
       " 'Gender/Orientation Match Accuracy': 1.0}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_knn_and_evaluate(20, x, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dadbd0-79d6-4026-ac22-70e247844997",
   "metadata": {},
   "source": [
    "### Model 3: 2 Word2vec_embeddings_scaled, all 111 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b247d16-f541-489d-b0c3-24f4aceefaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the string representation\n",
    "ok['word2vec_embeddings_scaled'] = (\n",
    "    ok['word2vec_embeddings_scaled']\n",
    "    .str.replace(r'\\s+', ',', regex=True)  # Replace multiple spaces with a single comma\n",
    "    .str.replace(',,', ',')  # Replace double commas with a single comma\n",
    "    .str.strip('[]')  # Remove square brackets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2454c60-0722-4b47-a481-de949692e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "# Convert the string representations to lists of floats\n",
    "ok['word2vec_embeddings_scaled'] = ok['word2vec_embeddings_scaled'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e9ab068-4de7-497f-a3b5-a674e0a0b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a NumPy array\n",
    "ok['word2vec_embeddings_scaled'] = ok['word2vec_embeddings_scaled'].apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a390f584-fe9c-4757-8df8-eb0afa0f4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Replace with your actual feature names\n",
    "X_word2vec = np.array(ok['word2vec_embeddings_scaled'].tolist())  # Convert to 2D array\n",
    "X_other = x.values \n",
    "X_combined = np.hstack((X_word2vec, X_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ca42b8c-be39-4099-bf26-bed315dddc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cat=ok.iloc[:,1:107]\n",
    "text=ok.iloc[:,112:113]\n",
    "x = pd.concat([num_cat, text], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f75844e3-67b3-4891-8739-a6a95e380d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_knn_and_evaluate(20, X_combined, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "029602e6-e62a-4fc2-add2-56e6d59245ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(X_word2vec_padded.shape[0] == X_other.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "655dfd68-4ccf-44f0-9f15-bd40e36e6d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59946, 407)\n"
     ]
    }
   ],
   "source": [
    "print(X_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c03ffbd-2107-4a44-8689-8d9df617af6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [0.76321473, 0.64034454, 0.58260717, 0.1941664...\n",
      "1    [0.65697592, 0.62005705, 0.59067174, 0.1890259...\n",
      "2    [0.70801798, 0.64246498, 0.52894441, 0.1918418...\n",
      "3    [0.65878697, 0.67627868, 0.53726614, 0.2329434...\n",
      "4    [0.62431777, 0.69718922, 0.49372216, 0.2371102...\n",
      "Name: word2vec_embeddings_scaled, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ok['word2vec_embeddings_scaled'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8a2577-d600-49bb-b3a2-c1c1741af28e",
   "metadata": {},
   "source": [
    "## Function to run several Kmean Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "475a86a4-7e44-45c8-ab71-008c46fda6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_and_find_similar(dataset=ok, X=None, n_clusters=12, n_similar=10):\n",
    "    \"\"\"\n",
    "    Runs K-Means clustering and finds the specified number of most similar individuals within each cluster.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: DataFrame, the dataset to use (default is 'ok')\n",
    "    - X: DataFrame, the feature vector\n",
    "    - n_clusters: int, number of clusters for K-Means (default=12)\n",
    "    - n_similar: int, number of similar individuals to return per person (default=10)\n",
    "    \n",
    "    Returns:\n",
    "    - Updated DataFrame with assigned clusters and specified number of most similar individuals per person\n",
    "    - Prints model evaluation metrics\n",
    "    \"\"\"\n",
    "    if X is None:\n",
    "        raise ValueError(\"Feature vector X must be provided\")\n",
    "    \n",
    "    # Fit K-Means model\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    dataset['cluster'] = kmeans.fit_predict(X)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    silhouette_avg = silhouette_score(X, dataset['cluster'])\n",
    "    davies_bouldin = davies_bouldin_score(X, dataset['cluster'])\n",
    "    calinski_harabasz = calinski_harabasz_score(X, dataset['cluster'])\n",
    "    \n",
    "    print(f\"Silhouette Score: {silhouette_avg:.4f}\")\n",
    "    print(f\"Davies-Bouldin Score: {davies_bouldin:.4f}\")\n",
    "    print(f\"Calinski-Harabasz Score: {calinski_harabasz:.4f}\")\n",
    "    \n",
    "    # Create a dictionary to store the most similar people for each individual\n",
    "    similar_people = {}\n",
    "    avg_match_distances = []\n",
    "    \n",
    "    # Find the closest people within each cluster\n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_indices = dataset[dataset['cluster'] == cluster].index\n",
    "        cluster_features = X.loc[cluster_indices]\n",
    "        distances = euclidean_distances(cluster_features)\n",
    "        \n",
    "        for i, index in enumerate(cluster_indices):\n",
    "            sorted_indices = np.argsort(distances[i])[1:n_similar+1]  # Exclude self (index 0)\n",
    "            similar_people[index] = cluster_indices[sorted_indices].tolist()\n",
    "            \n",
    "            # Compute average match distance for each person\n",
    "            avg_distance = np.mean(distances[i][sorted_indices])\n",
    "            avg_match_distances.append(avg_distance)\n",
    "    \n",
    "    # Compute overall Average Match Distance (AMD)\n",
    "    overall_avg_match_distance = np.mean(avg_match_distances)\n",
    "    print(f\"Average Match Distance (AMD): {overall_avg_match_distance:.4f}\")\n",
    "    \n",
    "    # Convert the dictionary into a DataFrame\n",
    "    similar_df = pd.DataFrame.from_dict(similar_people, orient='index')\n",
    "    similar_df.columns = [f'similar_{i+1}' for i in range(n_similar)]\n",
    "    \n",
    "    # Merge with the original dataset\n",
    "    dataset = dataset.merge(similar_df, left_index=True, right_index=True)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa82d989-e0eb-43a7-9c79-7de1d7a456a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.0300\n",
      "Davies-Bouldin Score: 3.9053\n",
      "Calinski-Harabasz Score: 1256.3048\n",
      "Average Match Distance (AMD): 3.0591\n",
      "CPU times: user 2min, sys: 51.2 s, total: 2min 51s\n",
      "Wall time: 51.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_and_find_similar(dataset=ok, X=x, n_clusters=12, n_similar=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa1ea08-a9d0-438f-acd0-33e44c1f60ce",
   "metadata": {},
   "source": [
    "## Function to run several Deep Collaborative Scoring Model (DCScam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ac639d7-94e8-4c13-a91d-4192bbd06717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "\n",
    "def run_dcscam_and_recommend(X, n_users, n_items, n_latent_factors=10, epochs=10, batch_size=64):\n",
    "    \"\"\"\n",
    "    Runs the Deep Collaborative Scoring Model (DCScam) and recommends similar individuals.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: A user-item matrix or feature matrix (users as rows, items as columns).\n",
    "    - n_users: Number of unique users.\n",
    "    - n_items: Number of unique items.\n",
    "    - n_latent_factors: Number of latent factors for embedding layers (default=10).\n",
    "    - epochs: Number of epochs to train the model (default=10).\n",
    "    - batch_size: Size of the batch for training (default=64).\n",
    "    \n",
    "    Returns:\n",
    "    - recommendations: A DataFrame of user recommendations.\n",
    "    \"\"\"\n",
    "    # Debugging: Check the input data\n",
    "    print(\"Input data (X):\")\n",
    "    print(X[:5])  # Print the first 5 rows of X\n",
    "\n",
    "    # Ensure X is a list of tuples (user, item, rating)\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = list(zip(X.iloc[:, 0], X.iloc[:, 1], X.iloc[:, 2]))  # Convert DataFrame to list of tuples\n",
    "    elif isinstance(X, np.ndarray):\n",
    "        X = list(zip(X[:, 0], X[:, 1], X[:, 2]))  # Convert NumPy array to list of tuples\n",
    "    elif isinstance(X, list):\n",
    "        pass  # X is already in the correct format\n",
    "    else:\n",
    "        raise ValueError(\"X must be a DataFrame, NumPy array, or list of tuples.\")\n",
    "\n",
    "    # Extract user, item, and rating data\n",
    "    user_data = np.array([x[0] for x in X], dtype=np.int32)  # Ensure integer type\n",
    "    item_data = np.array([x[1] for x in X], dtype=np.int32)  # Ensure integer type\n",
    "    ratings = np.array([x[2] for x in X], dtype=np.float32)  # Ensure float type\n",
    "\n",
    "    # Debugging: Check the extracted data\n",
    "    print(\"User data:\", user_data[:5])\n",
    "    print(\"Item data:\", item_data[:5])\n",
    "    print(\"Ratings:\", ratings[:5])\n",
    "\n",
    "    # Define the model architecture\n",
    "    user_input = Input(shape=(1,), name='user_input')\n",
    "    item_input = Input(shape=(1,), name='item_input')\n",
    "\n",
    "    user_embedding = Embedding(input_dim=n_users, output_dim=n_latent_factors, name='user_embedding')(user_input)\n",
    "    item_embedding = Embedding(input_dim=n_items, output_dim=n_latent_factors, name='item_embedding')(item_input)\n",
    "\n",
    "    user_flat = Flatten()(user_embedding)\n",
    "    item_flat = Flatten()(item_embedding)\n",
    "\n",
    "    concat = Concatenate()([user_flat, item_flat])\n",
    "    dense = Dense(128, activation='relu')(concat)\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "    model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit([user_data, item_data], ratings, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    # Predict the scores for all user-item pairs\n",
    "    predictions = model.predict([user_data, item_data])\n",
    "    \n",
    "    # Recommendation: Get top N items for each user\n",
    "    recommendations = {}\n",
    "    for user in range(n_users):\n",
    "        user_indices = np.where(user_data == user)[0]  # Find indices where user_data == user\n",
    "        user_predictions = predictions[user_indices]\n",
    "        top_items = item_data[user_indices][np.argsort(user_predictions.flatten())[::-1][:10]]  # Top 10 recommendations\n",
    "        recommendations[user] = top_items\n",
    "    \n",
    "    # Return recommendations as DataFrame\n",
    "    recommendations_df = pd.DataFrame.from_dict(recommendations, orient='index', columns=[f'Rec_{i+1}' for i in range(10)])\n",
    "    \n",
    "    return recommendations_df\n",
    "\n",
    "# Example usage\n",
    "# run_dcscam_and_recommend(X=x, n_users=59946, n_items=111, n_latent_factors=10, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ced4688-9687-43cb-844d-8bc74d414375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 111)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "657a5c33-eeb2-45f3-b3d4-631441b2de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data (X):\n",
      "   single  female  orientation_bisexual  orientation_gay  \\\n",
      "0       1       0                     0                0   \n",
      "1       1       0                     0                0   \n",
      "2       0       0                     0                0   \n",
      "3       1       0                     0                0   \n",
      "4       1       0                     0                0   \n",
      "\n",
      "   orientation_straight  body_type_athletic  body_type_average  \\\n",
      "0                     1                   0                  0   \n",
      "1                     1                   0                  1   \n",
      "2                     1                   0                  0   \n",
      "3                     1                   0                  0   \n",
      "4                     1                   1                  0   \n",
      "\n",
      "   body_type_curvy  body_type_fit  body_type_not_disclosed  ...  smokes_yes  \\\n",
      "0                0              0                        0  ...           1   \n",
      "1                0              0                        0  ...           0   \n",
      "2                0              0                        0  ...           0   \n",
      "3                0              0                        0  ...           0   \n",
      "4                0              0                        0  ...           0   \n",
      "\n",
      "   speaks_english  speaks_spanish  speaks_other  speaks_count  \\\n",
      "0               1               0             0             1   \n",
      "1               1               0             0             1   \n",
      "2               1               0             1             3   \n",
      "3               1               0             0             1   \n",
      "4               1               0             0             1   \n",
      "\n",
      "   topic_0_from_five  topic_1_from_five  topic_2_from_five  topic_3_from_five  \\\n",
      "0           0.905500           0.023574           0.023639           0.023778   \n",
      "1           0.027683           0.339134           0.027590           0.578125   \n",
      "2           0.914891           0.021284           0.021307           0.021207   \n",
      "3           0.045781           0.045620           0.817402           0.045673   \n",
      "4           0.031946           0.031976           0.872147           0.032119   \n",
      "\n",
      "   topic_4_from_five  \n",
      "0           0.023509  \n",
      "1           0.027468  \n",
      "2           0.021311  \n",
      "3           0.045524  \n",
      "4           0.031812  \n",
      "\n",
      "[5 rows x 111 columns]\n",
      "User data: [1 1 0 1 1]\n",
      "Item data: [0 0 0 0 0]\n",
      "Ratings: [0. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9396 - loss: 0.2349\n",
      "Epoch 2/10\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9545 - loss: 0.1653\n",
      "Epoch 3/10\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.1677\n",
      "Epoch 4/10\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1664\n",
      "Epoch 5/10\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9530 - loss: 0.1683\n",
      "Epoch 6/10\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1632\n",
      "Epoch 7/10\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1633\n",
      "Epoch 8/10\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1689\n",
      "Epoch 9/10\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1666\n",
      "Epoch 10/10\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1644\n",
      "\u001b[1m1874/1874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rec_1</th>\n",
       "      <th>Rec_2</th>\n",
       "      <th>Rec_3</th>\n",
       "      <th>Rec_4</th>\n",
       "      <th>Rec_5</th>\n",
       "      <th>Rec_6</th>\n",
       "      <th>Rec_7</th>\n",
       "      <th>Rec_8</th>\n",
       "      <th>Rec_9</th>\n",
       "      <th>Rec_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rec_1  Rec_2  Rec_3  Rec_4  Rec_5  Rec_6  Rec_7  Rec_8  Rec_9  Rec_10\n",
       "0        1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
       "1        1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0     1.0\n",
       "2        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN\n",
       "3        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN\n",
       "4        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN\n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
       "59941    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN\n",
       "59942    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN\n",
       "59943    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN\n",
       "59944    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN\n",
       "59945    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN\n",
       "\n",
       "[59946 rows x 10 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dcscam_and_recommend(X=x, n_users=59946, n_items=111, n_latent_factors=10, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8ef653-e7ac-40ba-a908-645a935f183d",
   "metadata": {},
   "source": [
    "## Function to run several Bayesian Personalized Ranking (BPR) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5addafa-089b-4144-80b6-3cf6fdb8b0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 111)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ccd6467-6814-4ba2-8ebe-f0501085e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def run_bpr_and_recommend(X, n_users, n_items, factors=10, iterations=50):\n",
    "    \"\"\"\n",
    "    Runs the Bayesian Personalized Ranking (BPR) model and recommends similar individuals.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: A user-item interaction DataFrame (users as rows, items as columns).\n",
    "    - n_users: Number of unique users.\n",
    "    - n_items: Number of unique items.\n",
    "    - factors: Number of latent factors for the BPR model (default=10).\n",
    "    - iterations: Number of iterations to train the BPR model (default=50).\n",
    "    \n",
    "    Returns:\n",
    "    - recommendations: A DataFrame of user recommendations.\n",
    "    \"\"\"\n",
    "    # Convert the DataFrame to a sparse CSR matrix\n",
    "    interaction_matrix = csr_matrix(X.values.astype('float32'))\n",
    "\n",
    "    # Debugging: Check the shape of the interaction matrix\n",
    "    print(\"Shape of interaction_matrix:\", interaction_matrix.shape)\n",
    "\n",
    "    # Initialize the BPR model\n",
    "    bpr_model = implicit.bpr.BayesianPersonalizedRanking(factors=factors, iterations=iterations)\n",
    "\n",
    "    # Train the BPR model\n",
    "    bpr_model.fit(interaction_matrix)\n",
    "\n",
    "    # Generate recommendations for each user\n",
    "    recommendations = {}\n",
    "    for user in range(n_users):\n",
    "        # Ensure the user_items matrix is in CSR format\n",
    "        user_items_csr = interaction_matrix.tocsr()\n",
    "        user_recommendations = bpr_model.recommend(user, user_items_csr, N=10)  # Top 10 recommendations\n",
    "        recommendations[user] = user_recommendations[0]  # Extract item IDs\n",
    "\n",
    "    # Convert recommendations to DataFrame\n",
    "    recommendations_df = pd.DataFrame.from_dict(recommendations, orient='index', columns=[f'Rec_{i+1}' for i in range(10)])\n",
    "\n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12bb5383-f120-4983-a1a7-b7b56fbb1fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of interaction_matrix: (59946, 111)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3144ce7d31fa42e4bf410a4a60909620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "user_items must contain 1 row for every user in userids",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_bpr_and_recommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_users\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m59946\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m111\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 37\u001b[0m, in \u001b[0;36mrun_bpr_and_recommend\u001b[0;34m(X, n_users, n_items, factors, iterations)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_users):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Ensure the user_items matrix is in CSR format\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     user_items_csr \u001b[38;5;241m=\u001b[39m interaction_matrix\u001b[38;5;241m.\u001b[39mtocsr()\n\u001b[0;32m---> 37\u001b[0m     user_recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mbpr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_items_csr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Top 10 recommendations\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     recommendations[user] \u001b[38;5;241m=\u001b[39m user_recommendations[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Extract item IDs\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Convert recommendations to DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/amooora/lib/python3.10/site-packages/implicit/cpu/matrix_factorization_base.py:49\u001b[0m, in \u001b[0;36mMatrixFactorizationBase.recommend\u001b[0;34m(self, userid, user_items, N, filter_already_liked_items, filter_items, recalculate_user, items)\u001b[0m\n\u001b[1;32m     47\u001b[0m     user_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(userid) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(userid)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_items\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m user_count:\n\u001b[0;32m---> 49\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_items must contain 1 row for every user in userids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_factor(userid, user_items, recalculate_user)\n\u001b[1;32m     53\u001b[0m item_factors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_factors\n",
      "\u001b[0;31mValueError\u001b[0m: user_items must contain 1 row for every user in userids"
     ]
    }
   ],
   "source": [
    "run_bpr_and_recommend(X=x, n_users=59946, n_items=111, factors=10, iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d8019-4fce-4d14-8680-08e0d8b30815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
