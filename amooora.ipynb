{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tfelipelli/code/ninamcunha/amooora'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "ok = pd.read_csv(\"raw_data/okcupid_profiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'status', 'sex', 'orientation', 'body_type', 'diet', 'drinks',\n",
       "       'drugs', 'education', 'ethnicity', 'height', 'income', 'job',\n",
       "       'last_online', 'location', 'offspring', 'pets', 'religion', 'sign',\n",
       "       'smokes', 'speaks', 'essay0', 'essay1', 'essay2', 'essay3', 'essay4',\n",
       "       'essay5', 'essay6', 'essay7', 'essay8', 'essay9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping essay columns that will not be analysed here\n",
    "ok = ok.drop(columns=['essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7', 'essay8', 'essay9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>2012-06-28-14-22</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn't want kids</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>2012-06-27-21-26</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     status sex orientation       body_type               diet  \\\n",
       "0   22     single   m    straight  a little extra  strictly anything   \n",
       "1   35     single   m    straight         average       mostly other   \n",
       "2   38  available   m    straight            thin           anything   \n",
       "3   23     single   m    straight            thin         vegetarian   \n",
       "4   29     single   m    straight        athletic                NaN   \n",
       "\n",
       "     drinks      drugs                          education  \\\n",
       "0  socially      never      working on college/university   \n",
       "1     often  sometimes              working on space camp   \n",
       "2  socially        NaN     graduated from masters program   \n",
       "3  socially        NaN      working on college/university   \n",
       "4  socially      never  graduated from college/university   \n",
       "\n",
       "             ethnicity  ...  income                          job  \\\n",
       "0         asian, white  ...      -1               transportation   \n",
       "1                white  ...   80000         hospitality / travel   \n",
       "2                  NaN  ...      -1                          NaN   \n",
       "3                white  ...   20000                      student   \n",
       "4  asian, black, other  ...      -1  artistic / musical / writer   \n",
       "\n",
       "        last_online                         location  \\\n",
       "0  2012-06-28-20-30  south san francisco, california   \n",
       "1  2012-06-29-21-41              oakland, california   \n",
       "2  2012-06-27-09-10        san francisco, california   \n",
       "3  2012-06-28-14-22             berkeley, california   \n",
       "4  2012-06-27-21-26        san francisco, california   \n",
       "\n",
       "                                offspring                       pets  \\\n",
       "0  doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "1  doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "2                                     NaN                   has cats   \n",
       "3                       doesn't want kids                 likes cats   \n",
       "4                                     NaN  likes dogs and likes cats   \n",
       "\n",
       "                                   religion  \\\n",
       "0     agnosticism and very serious about it   \n",
       "1  agnosticism but not too serious about it   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks  \n",
       "0                                            english  \n",
       "1  english (fluently), spanish (poorly), french (...  \n",
       "2                               english, french, c++  \n",
       "3                           english, german (poorly)  \n",
       "4                                            english  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   status       59946 non-null  object \n",
      " 2   sex          59946 non-null  object \n",
      " 3   orientation  59946 non-null  object \n",
      " 4   body_type    54650 non-null  object \n",
      " 5   diet         35551 non-null  object \n",
      " 6   drinks       56961 non-null  object \n",
      " 7   drugs        45866 non-null  object \n",
      " 8   education    53318 non-null  object \n",
      " 9   ethnicity    54266 non-null  object \n",
      " 10  height       59943 non-null  float64\n",
      " 11  income       59946 non-null  int64  \n",
      " 12  job          51748 non-null  object \n",
      " 13  last_online  59946 non-null  object \n",
      " 14  location     59946 non-null  object \n",
      " 15  offspring    24385 non-null  object \n",
      " 16  pets         40025 non-null  object \n",
      " 17  religion     39720 non-null  object \n",
      " 18  sign         48890 non-null  object \n",
      " 19  smokes       54434 non-null  object \n",
      " 20  speaks       59896 non-null  object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 9.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# summary of the dataset\n",
    "ok.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59946.000000</td>\n",
       "      <td>59943.000000</td>\n",
       "      <td>59946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.340290</td>\n",
       "      <td>68.295281</td>\n",
       "      <td>20033.222534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.452779</td>\n",
       "      <td>3.994803</td>\n",
       "      <td>97346.192104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        height          income\n",
       "count  59946.000000  59943.000000    59946.000000\n",
       "mean      32.340290     68.295281    20033.222534\n",
       "std        9.452779      3.994803    97346.192104\n",
       "min       18.000000      1.000000       -1.000000\n",
       "25%       26.000000     66.000000       -1.000000\n",
       "50%       30.000000     68.000000       -1.000000\n",
       "75%       37.000000     71.000000       -1.000000\n",
       "max      110.000000     95.000000  1000000.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical summary of numerical features\n",
    "ok.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               54\n",
       "status             5\n",
       "sex                2\n",
       "orientation        3\n",
       "body_type         12\n",
       "diet              18\n",
       "drinks             6\n",
       "drugs              3\n",
       "education         32\n",
       "ethnicity        217\n",
       "height            60\n",
       "income            13\n",
       "job               21\n",
       "last_online    30123\n",
       "location         199\n",
       "offspring         15\n",
       "pets              15\n",
       "religion          45\n",
       "sign              48\n",
       "smokes             5\n",
       "speaks          7647\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values in each column\n",
    "ok.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offspring      0.59\n",
       "diet           0.41\n",
       "religion       0.34\n",
       "pets           0.33\n",
       "drugs          0.23\n",
       "sign           0.18\n",
       "job            0.14\n",
       "education      0.11\n",
       "ethnicity      0.09\n",
       "smokes         0.09\n",
       "body_type      0.09\n",
       "drinks         0.05\n",
       "speaks         0.00\n",
       "height         0.00\n",
       "sex            0.00\n",
       "status         0.00\n",
       "age            0.00\n",
       "orientation    0.00\n",
       "income         0.00\n",
       "last_online    0.00\n",
       "location       0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % of missing values in each column\n",
    "round(ok.isnull().sum().sort_values(ascending=False)/len(ok), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decide what to do for each column with missing values...\n",
    "Investigate missing values in each column then choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median using `SimpleImputer` from Scikit-Learn\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe using the chosen method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i \"sort of\" did option 3 for all of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `offspring`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offspring\n",
       "NaN                                        35561\n",
       "doesn't have kids                           7560\n",
       "doesn't have kids, but might want them      3875\n",
       "doesn't have kids, but wants them           3565\n",
       "doesn't want kids                           2927\n",
       "has kids                                    1883\n",
       "has a kid                                   1881\n",
       "doesn't have kids, and doesn't want any     1132\n",
       "has kids, but doesn't want more              442\n",
       "has a kid, but doesn't want more             275\n",
       "has a kid, and might want more               231\n",
       "wants kids                                   225\n",
       "might want kids                              182\n",
       "has kids, and might want more                115\n",
       "has a kid, and wants more                     71\n",
       "has kids, and wants more                      21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.offspring.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"NoDisclosed\"\n",
    "# ok.offspring.replace(np.nan, \"NotDisclosed\", inplace=True)\n",
    "ok.loc[ok.offspring.isna(),\"offspring\"] = \"NotDisclosed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok[\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `diet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diet\n",
       "NaN                    24395\n",
       "mostly anything        16585\n",
       "anything                6183\n",
       "strictly anything       5113\n",
       "mostly vegetarian       3444\n",
       "mostly other            1007\n",
       "strictly vegetarian      875\n",
       "vegetarian               667\n",
       "strictly other           452\n",
       "mostly vegan             338\n",
       "other                    331\n",
       "strictly vegan           228\n",
       "vegan                    136\n",
       "mostly kosher             86\n",
       "mostly halal              48\n",
       "strictly halal            18\n",
       "strictly kosher           18\n",
       "halal                     11\n",
       "kosher                    11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.diet.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"NotDiet\"\n",
    "ok.loc[ok.diet.isna(),\"diet\"] = \"NoDiet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `religion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion\n",
       "NaN                                           20226\n",
       "agnosticism                                    2724\n",
       "other                                          2691\n",
       "agnosticism but not too serious about it       2636\n",
       "agnosticism and laughing about it              2496\n",
       "catholicism but not too serious about it       2318\n",
       "atheism                                        2175\n",
       "other and laughing about it                    2119\n",
       "atheism and laughing about it                  2074\n",
       "christianity                                   1957\n",
       "christianity but not too serious about it      1952\n",
       "other but not too serious about it             1554\n",
       "judaism but not too serious about it           1517\n",
       "atheism but not too serious about it           1318\n",
       "catholicism                                    1064\n",
       "christianity and somewhat serious about it      927\n",
       "atheism and somewhat serious about it           848\n",
       "other and somewhat serious about it             846\n",
       "catholicism and laughing about it               726\n",
       "judaism and laughing about it                   681\n",
       "buddhism but not too serious about it           650\n",
       "agnosticism and somewhat serious about it       642\n",
       "judaism                                         612\n",
       "christianity and very serious about it          578\n",
       "atheism and very serious about it               570\n",
       "catholicism and somewhat serious about it       548\n",
       "other and very serious about it                 533\n",
       "buddhism and laughing about it                  466\n",
       "buddhism                                        403\n",
       "christianity and laughing about it              373\n",
       "buddhism and somewhat serious about it          359\n",
       "agnosticism and very serious about it           314\n",
       "judaism and somewhat serious about it           266\n",
       "hinduism but not too serious about it           227\n",
       "hinduism                                        107\n",
       "catholicism and very serious about it           102\n",
       "buddhism and very serious about it               70\n",
       "hinduism and somewhat serious about it           58\n",
       "islam                                            48\n",
       "hinduism and laughing about it                   44\n",
       "islam but not too serious about it               40\n",
       "islam and somewhat serious about it              22\n",
       "judaism and very serious about it                22\n",
       "islam and laughing about it                      16\n",
       "hinduism and very serious about it               14\n",
       "islam and very serious about it                  13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.religion.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"NotReligion\"\n",
    "ok.loc[ok.religion.isna(),\"religion\"] = \"NoReligion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pets\n",
       "NaN                                19921\n",
       "likes dogs and likes cats          14814\n",
       "likes dogs                          7224\n",
       "likes dogs and has cats             4313\n",
       "has dogs                            4134\n",
       "has dogs and likes cats             2333\n",
       "likes dogs and dislikes cats        2029\n",
       "has dogs and has cats               1474\n",
       "has cats                            1406\n",
       "likes cats                          1063\n",
       "has dogs and dislikes cats           552\n",
       "dislikes dogs and likes cats         240\n",
       "dislikes dogs and dislikes cats      196\n",
       "dislikes cats                        122\n",
       "dislikes dogs and has cats            81\n",
       "dislikes dogs                         44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.pets.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"NotPets\"\n",
    "ok.loc[ok.pets.isna(),\"pets\"] = \"NoPets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `drugs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugs\n",
       "never        37724\n",
       "NaN          14080\n",
       "sometimes     7732\n",
       "often          410\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.drugs.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"NotDrugs\"  \n",
    "ok.loc[ok.drugs.isna(),\"drugs\"] = \"NoDrugs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sign`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign\n",
       "NaN                                              11056\n",
       "gemini and it&rsquo;s fun to think about          1782\n",
       "scorpio and it&rsquo;s fun to think about         1772\n",
       "leo and it&rsquo;s fun to think about             1692\n",
       "libra and it&rsquo;s fun to think about           1649\n",
       "taurus and it&rsquo;s fun to think about          1640\n",
       "cancer and it&rsquo;s fun to think about          1597\n",
       "pisces and it&rsquo;s fun to think about          1592\n",
       "sagittarius and it&rsquo;s fun to think about     1583\n",
       "virgo and it&rsquo;s fun to think about           1574\n",
       "aries and it&rsquo;s fun to think about           1573\n",
       "aquarius and it&rsquo;s fun to think about        1503\n",
       "virgo but it doesn&rsquo;t matter                 1497\n",
       "leo but it doesn&rsquo;t matter                   1457\n",
       "cancer but it doesn&rsquo;t matter                1454\n",
       "gemini but it doesn&rsquo;t matter                1453\n",
       "taurus but it doesn&rsquo;t matter                1450\n",
       "aquarius but it doesn&rsquo;t matter              1408\n",
       "libra but it doesn&rsquo;t matter                 1408\n",
       "capricorn and it&rsquo;s fun to think about       1376\n",
       "sagittarius but it doesn&rsquo;t matter           1375\n",
       "aries but it doesn&rsquo;t matter                 1373\n",
       "capricorn but it doesn&rsquo;t matter             1319\n",
       "pisces but it doesn&rsquo;t matter                1300\n",
       "scorpio but it doesn&rsquo;t matter               1264\n",
       "leo                                               1159\n",
       "libra                                             1098\n",
       "cancer                                            1092\n",
       "virgo                                             1029\n",
       "scorpio                                           1020\n",
       "gemini                                            1013\n",
       "taurus                                            1001\n",
       "aries                                              996\n",
       "pisces                                             992\n",
       "aquarius                                           954\n",
       "sagittarius                                        937\n",
       "capricorn                                          833\n",
       "scorpio and it matters a lot                        78\n",
       "leo and it matters a lot                            66\n",
       "cancer and it matters a lot                         63\n",
       "aquarius and it matters a lot                       63\n",
       "gemini and it matters a lot                         62\n",
       "pisces and it matters a lot                         62\n",
       "libra and it matters a lot                          52\n",
       "taurus and it matters a lot                         49\n",
       "sagittarius and it matters a lot                    47\n",
       "aries and it matters a lot                          47\n",
       "capricorn and it matters a lot                      45\n",
       "virgo and it matters a lot                          41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.sign.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"NotDisclosed\"\n",
    "ok.loc[ok.sign.isna(),\"sign\"] = \"NotDisclosed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `job`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job\n",
       "NaN                                  8198\n",
       "other                                7589\n",
       "student                              4882\n",
       "science / tech / engineering         4848\n",
       "computer / hardware / software       4709\n",
       "artistic / musical / writer          4439\n",
       "sales / marketing / biz dev          4391\n",
       "medicine / health                    3680\n",
       "education / academia                 3513\n",
       "executive / management               2373\n",
       "banking / financial / real estate    2266\n",
       "entertainment / media                2250\n",
       "law / legal services                 1381\n",
       "hospitality / travel                 1364\n",
       "construction / craftsmanship         1021\n",
       "clerical / administrative             805\n",
       "political / government                708\n",
       "rather not say                        436\n",
       "transportation                        366\n",
       "unemployed                            273\n",
       "retired                               250\n",
       "military                              204\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.job.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"NotDisclosed\"\n",
    "ok.loc[ok.job.isna(),\"job\"] = \"NotDisclosed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `education`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       "graduated from college/university    23959\n",
       "graduated from masters program        8961\n",
       "NaN                                   6628\n",
       "working on college/university         5712\n",
       "working on masters program            1683\n",
       "graduated from two-year college       1531\n",
       "graduated from high school            1428\n",
       "graduated from ph.d program           1272\n",
       "graduated from law school             1122\n",
       "working on two-year college           1074\n",
       "dropped out of college/university      995\n",
       "working on ph.d program                983\n",
       "college/university                     801\n",
       "graduated from space camp              657\n",
       "dropped out of space camp              523\n",
       "graduated from med school              446\n",
       "working on space camp                  445\n",
       "working on law school                  269\n",
       "two-year college                       222\n",
       "working on med school                  212\n",
       "dropped out of two-year college        191\n",
       "dropped out of masters program         140\n",
       "masters program                        136\n",
       "dropped out of ph.d program            127\n",
       "dropped out of high school             102\n",
       "high school                             96\n",
       "working on high school                  87\n",
       "space camp                              58\n",
       "ph.d program                            26\n",
       "law school                              19\n",
       "dropped out of law school               18\n",
       "dropped out of med school               12\n",
       "med school                              11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.education.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"NotDisclosed\"\n",
    "ok.loc[ok.education.isna(),\"education\"] = \"NotDisclosed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ethnicity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ethnicity\n",
       "white                                                                               32831\n",
       "asian                                                                                6134\n",
       "NaN                                                                                  5680\n",
       "hispanic / latin                                                                     2823\n",
       "black                                                                                2008\n",
       "                                                                                    ...  \n",
       "asian, black, pacific islander, hispanic / latin, white                                 1\n",
       "asian, native american, indian, pacific islander, hispanic / latin, white, other        1\n",
       "asian, middle eastern, black, pacific islander, hispanic / latin                        1\n",
       "asian, black, pacific islander, white, other                                            1\n",
       "asian, black, indian                                                                    1\n",
       "Name: count, Length: 218, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.ethnicity.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asian, white', 'white', nan, 'asian, black, other',\n",
       "       'white, other', 'hispanic / latin, white', 'hispanic / latin',\n",
       "       'pacific islander, white', 'asian', 'black, white',\n",
       "       'pacific islander', 'asian, native american',\n",
       "       'asian, pacific islander', 'black, native american, white',\n",
       "       'middle eastern, other', 'native american, white', 'indian',\n",
       "       'black', 'black, native american, hispanic / latin, other',\n",
       "       'black, native american, hispanic / latin',\n",
       "       'asian, black, pacific islander',\n",
       "       'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other',\n",
       "       'other', 'hispanic / latin, other', 'asian, black',\n",
       "       'middle eastern, white', 'native american, white, other',\n",
       "       'black, native american', 'black, white, other',\n",
       "       'hispanic / latin, white, other', 'middle eastern', 'black, other',\n",
       "       'native american, hispanic / latin, white', 'black, indian',\n",
       "       'indian, white, other', 'middle eastern, indian, other',\n",
       "       'black, native american, hispanic / latin, white, other',\n",
       "       'pacific islander, hispanic / latin',\n",
       "       'black, hispanic / latin, white', 'native american',\n",
       "       'indian, white', 'asian, white, other', 'black, hispanic / latin',\n",
       "       'asian, hispanic / latin, white',\n",
       "       'middle eastern, hispanic / latin',\n",
       "       'asian, black, native american, pacific islander, white',\n",
       "       'middle eastern, indian', 'asian, indian',\n",
       "       'pacific islander, other', 'black, native american, white, other',\n",
       "       'black, pacific islander',\n",
       "       'middle eastern, native american, white',\n",
       "       'asian, native american, white, other',\n",
       "       'pacific islander, hispanic / latin, white', 'indian, other',\n",
       "       'asian, pacific islander, other', 'black, hispanic / latin, other',\n",
       "       'asian, black, native american',\n",
       "       'black, native american, hispanic / latin, white',\n",
       "       'native american, hispanic / latin', 'indian, hispanic / latin',\n",
       "       'native american, pacific islander',\n",
       "       'asian, black, native american, hispanic / latin, white',\n",
       "       'asian, black, white',\n",
       "       'asian, black, native american, pacific islander, other',\n",
       "       'middle eastern, hispanic / latin, white',\n",
       "       'asian, pacific islander, white',\n",
       "       'asian, native american, hispanic / latin, white, other',\n",
       "       'asian, hispanic / latin', 'asian, pacific islander, white, other',\n",
       "       'middle eastern, white, other',\n",
       "       'asian, pacific islander, hispanic / latin',\n",
       "       'black, native american, indian, other',\n",
       "       'native american, hispanic / latin, white, other',\n",
       "       'black, native american, other', 'asian, other',\n",
       "       'middle eastern, hispanic / latin, other',\n",
       "       'pacific islander, hispanic / latin, white, other',\n",
       "       'asian, black, hispanic / latin',\n",
       "       'asian, pacific islander, hispanic / latin, white',\n",
       "       'asian, black, native american, white',\n",
       "       'asian, middle eastern, white, other',\n",
       "       'native american, pacific islander, hispanic / latin',\n",
       "       'asian, native american, white',\n",
       "       'native american, pacific islander, hispanic / latin, white, other',\n",
       "       'indian, pacific islander', 'asian, middle eastern, black',\n",
       "       'asian, middle eastern, indian', 'asian, middle eastern, white',\n",
       "       'pacific islander, white, other',\n",
       "       'black, pacific islander, hispanic / latin',\n",
       "       'asian, middle eastern', 'asian, hispanic / latin, other',\n",
       "       'middle eastern, black, native american, indian, white, other',\n",
       "       'middle eastern, pacific islander, other', 'middle eastern, black',\n",
       "       'asian, indian, pacific islander',\n",
       "       'black, native american, pacific islander',\n",
       "       'native american, indian',\n",
       "       'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white',\n",
       "       'black, indian, other',\n",
       "       'asian, middle eastern, indian, hispanic / latin, white, other',\n",
       "       'middle eastern, black, white',\n",
       "       'asian, hispanic / latin, white, other',\n",
       "       'native american, hispanic / latin, other',\n",
       "       'middle eastern, black, pacific islander, white',\n",
       "       'asian, black, native american, hispanic / latin',\n",
       "       'native american, other', 'black, indian, white',\n",
       "       'asian, native american, hispanic / latin, white',\n",
       "       'black, native american, indian, white',\n",
       "       'middle eastern, black, indian, pacific islander, hispanic / latin, white',\n",
       "       'middle eastern, hispanic / latin, white, other',\n",
       "       'asian, black, native american, other',\n",
       "       'native american, pacific islander, hispanic / latin, white',\n",
       "       'asian, indian, other',\n",
       "       'middle eastern, native american, hispanic / latin, white, other',\n",
       "       'asian, middle eastern, black, pacific islander, hispanic / latin, white',\n",
       "       'black, native american, pacific islander, hispanic / latin, white, other',\n",
       "       'asian, middle eastern, native american, hispanic / latin, white',\n",
       "       'asian, middle eastern, black, native american, pacific islander, hispanic / latin, white, other',\n",
       "       'asian, indian, white',\n",
       "       'native american, pacific islander, white, other',\n",
       "       'middle eastern, black, native american, indian, pacific islander, hispanic / latin, white',\n",
       "       'asian, middle eastern, other', 'middle eastern, pacific islander',\n",
       "       'asian, black, hispanic / latin, other',\n",
       "       'asian, middle eastern, black, native american, hispanic / latin, white',\n",
       "       'middle eastern, black, hispanic / latin',\n",
       "       'black, pacific islander, white',\n",
       "       'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, other',\n",
       "       'middle eastern, black, native american, indian, hispanic / latin, white',\n",
       "       'asian, pacific islander, hispanic / latin, white, other',\n",
       "       'middle eastern, indian, white', 'asian, indian, white, other',\n",
       "       'middle eastern, black, native american, white, other',\n",
       "       'black, native american, pacific islander, other',\n",
       "       'middle eastern, black, native american, white',\n",
       "       'asian, indian, pacific islander, other',\n",
       "       'asian, black, native american, white, other',\n",
       "       'black, indian, hispanic / latin, white',\n",
       "       'asian, middle eastern, black, native american, indian, pacific islander, white',\n",
       "       'asian, black, pacific islander, hispanic / latin',\n",
       "       'middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other',\n",
       "       'asian, black, native american, indian',\n",
       "       'asian, black, indian, hispanic / latin, other',\n",
       "       'indian, hispanic / latin, other',\n",
       "       'asian, indian, hispanic / latin',\n",
       "       'asian, native american, pacific islander, white, other',\n",
       "       'asian, black, native american, indian, hispanic / latin, white, other',\n",
       "       'asian, indian, hispanic / latin, white',\n",
       "       'pacific islander, hispanic / latin, other',\n",
       "       'asian, indian, pacific islander, hispanic / latin, white, other',\n",
       "       'indian, hispanic / latin, white',\n",
       "       'asian, native american, pacific islander, hispanic / latin, white, other',\n",
       "       'asian, pacific islander, hispanic / latin, other',\n",
       "       'asian, black, hispanic / latin, white, other',\n",
       "       'black, indian, hispanic / latin',\n",
       "       'middle eastern, black, native american, hispanic / latin, white',\n",
       "       'black, pacific islander, other',\n",
       "       'black, native american, pacific islander, white',\n",
       "       'asian, black, native american, pacific islander',\n",
       "       'asian, indian, hispanic / latin, other',\n",
       "       'middle eastern, native american',\n",
       "       'middle eastern, native american, hispanic / latin',\n",
       "       'black, hispanic / latin, white, other',\n",
       "       'asian, native american, pacific islander, hispanic / latin, white',\n",
       "       'asian, native american, hispanic / latin',\n",
       "       'black, native american, indian, hispanic / latin, white, other',\n",
       "       'asian, middle eastern, hispanic / latin, white',\n",
       "       'black, native american, pacific islander, white, other',\n",
       "       'native american, indian, pacific islander, hispanic / latin',\n",
       "       'black, indian, white, other',\n",
       "       'asian, middle eastern, native american, pacific islander, hispanic / latin, white, other',\n",
       "       'native american, pacific islander, white',\n",
       "       'middle eastern, indian, white, other',\n",
       "       'asian, black, white, other',\n",
       "       'middle eastern, native american, hispanic / latin, white',\n",
       "       'indian, hispanic / latin, white, other',\n",
       "       'asian, middle eastern, black, pacific islander',\n",
       "       'asian, middle eastern, black, indian, pacific islander, hispanic / latin, white',\n",
       "       'asian, middle eastern, indian, other',\n",
       "       'asian, middle eastern, black, white, other',\n",
       "       'black, native american, pacific islander, hispanic / latin, white',\n",
       "       'black, native american, indian, pacific islander, hispanic / latin',\n",
       "       'asian, black, pacific islander, white',\n",
       "       'middle eastern, pacific islander, hispanic / latin',\n",
       "       'black, native american, indian, white, other',\n",
       "       'asian, black, hispanic / latin, white',\n",
       "       'asian, black, native american, indian, pacific islander, white',\n",
       "       'asian, black, native american, indian, pacific islander, hispanic / latin',\n",
       "       'asian, middle eastern, hispanic / latin, white, other',\n",
       "       'middle eastern, black, native american, indian',\n",
       "       'asian, native american, pacific islander',\n",
       "       'asian, black, native american, pacific islander, white, other',\n",
       "       'asian, middle eastern, hispanic / latin',\n",
       "       'asian, black, pacific islander, other',\n",
       "       'asian, native american, indian, pacific islander, hispanic / latin, white',\n",
       "       'middle eastern, native american, white, other',\n",
       "       'asian, native american, hispanic / latin, other',\n",
       "       'native american, indian, white',\n",
       "       'black, native american, pacific islander, hispanic / latin',\n",
       "       'asian, native american, pacific islander, white',\n",
       "       'black, native american, indian',\n",
       "       'indian, pacific islander, hispanic / latin, white',\n",
       "       'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin',\n",
       "       'asian, middle eastern, indian, hispanic / latin',\n",
       "       'asian, middle eastern, native american, pacific islander, other',\n",
       "       'black, native american, indian, pacific islander',\n",
       "       'asian, middle eastern, native american, pacific islander, white, other',\n",
       "       'asian, native american, other', 'middle eastern, black, other',\n",
       "       'asian, black, pacific islander, hispanic / latin, white',\n",
       "       'asian, middle eastern, native american, indian, pacific islander, hispanic / latin, white',\n",
       "       'asian, native american, indian, pacific islander, hispanic / latin, white, other',\n",
       "       'asian, middle eastern, black, pacific islander, hispanic / latin',\n",
       "       'asian, black, pacific islander, white, other',\n",
       "       'asian, black, indian'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok.ethnicity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"NotDisclosed\"\n",
    "ok.loc[ok.ethnicity.isna(),\"ethnicity\"] = \"NotDisclosed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `smokes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smokes\n",
       "no                43896\n",
       "NaN                5512\n",
       "sometimes          3787\n",
       "when drinking      3040\n",
       "yes                2231\n",
       "trying to quit     1480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.smokes.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"NotDisclosed\"\n",
    "ok.loc[ok.smokes.isna(),\"smokes\"] = \"NotDisclosed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `body type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body_type\n",
       "average           14652\n",
       "fit               12711\n",
       "athletic          11819\n",
       "NaN                5296\n",
       "thin               4711\n",
       "curvy              3924\n",
       "a little extra     2629\n",
       "skinny             1777\n",
       "full figured       1009\n",
       "overweight          444\n",
       "jacked              421\n",
       "used up             355\n",
       "rather not say      198\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.body_type.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"RatherNotSay\"\n",
    "ok.loc[ok.body_type.isna(),\"body_type\"] = \"RatherNotSay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing same text with spaces with \"RatherNotSay\"\n",
    "ok.loc[ok.body_type == \"rather not say\", \"body_type\"] = \"RatherNotSay\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `drinks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drinks\n",
       "socially       41780\n",
       "rarely          5957\n",
       "often           5164\n",
       "not at all      3267\n",
       "NaN             2985\n",
       "very often       471\n",
       "desperately      322\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.drinks.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"NotDisclosed\"\n",
    "ok.loc[ok.drinks.isna(),\"drinks\"] = \"NotDisclosed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `speaks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaks\n",
       "english                                                                                              21828\n",
       "english (fluently)                                                                                    6628\n",
       "english (fluently), spanish (poorly)                                                                  2059\n",
       "english (fluently), spanish (okay)                                                                    1917\n",
       "english (fluently), spanish (fluently)                                                                1288\n",
       "                                                                                                     ...  \n",
       "english (fluently), polish (fluently), french (poorly), hungarian (poorly), italian (poorly)             1\n",
       "english, spanish (fluently), hindi (okay), french (poorly)                                               1\n",
       "english (okay), spanish (okay), hebrew (okay)                                                            1\n",
       "english (fluently), slovenian (fluently), serbian (fluently), croatian (fluently), greek (poorly)        1\n",
       "english (fluently), russian (fluently), japanese (poorly), spanish (poorly), c++ (fluently)              1\n",
       "Name: count, Length: 7648, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and their count\n",
    "ok.speaks.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN with \"english\"\n",
    "ok.loc[ok.speaks.isna(),\"speaks\"] = \"english\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking i no longer have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "height         0.0\n",
       "status         0.0\n",
       "sex            0.0\n",
       "orientation    0.0\n",
       "age            0.0\n",
       "body_type      0.0\n",
       "diet           0.0\n",
       "drugs          0.0\n",
       "drinks         0.0\n",
       "education      0.0\n",
       "ethnicity      0.0\n",
       "income         0.0\n",
       "job            0.0\n",
       "last_online    0.0\n",
       "location       0.0\n",
       "offspring      0.0\n",
       "pets           0.0\n",
       "religion       0.0\n",
       "sign           0.0\n",
       "smokes         0.0\n",
       "speaks         0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NaN percentage for each column\n",
    "round(ok.isnull().sum().sort_values(ascending=False)/len(ok),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## writing csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NoDrugs</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NotDisclosed</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NotDisclosed</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NoKids</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NoReligion</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NoDrugs</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>2012-06-28-14-22</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn't want kids</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NoReligion</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NoDiet</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>2012-06-27-21-26</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NoKids</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NoReligion</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     status sex orientation       body_type               diet  \\\n",
       "0   22     single   m    straight  a little extra  strictly anything   \n",
       "1   35     single   m    straight         average       mostly other   \n",
       "2   38  available   m    straight            thin           anything   \n",
       "3   23     single   m    straight            thin         vegetarian   \n",
       "4   29     single   m    straight        athletic             NoDiet   \n",
       "\n",
       "     drinks      drugs                          education  \\\n",
       "0  socially      never      working on college/university   \n",
       "1     often  sometimes              working on space camp   \n",
       "2  socially    NoDrugs     graduated from masters program   \n",
       "3  socially    NoDrugs      working on college/university   \n",
       "4  socially      never  graduated from college/university   \n",
       "\n",
       "             ethnicity  ...  income                          job  \\\n",
       "0         asian, white  ...      -1               transportation   \n",
       "1                white  ...   80000         hospitality / travel   \n",
       "2         NotDisclosed  ...      -1                 NotDisclosed   \n",
       "3                white  ...   20000                      student   \n",
       "4  asian, black, other  ...      -1  artistic / musical / writer   \n",
       "\n",
       "        last_online                         location  \\\n",
       "0  2012-06-28-20-30  south san francisco, california   \n",
       "1  2012-06-29-21-41              oakland, california   \n",
       "2  2012-06-27-09-10        san francisco, california   \n",
       "3  2012-06-28-14-22             berkeley, california   \n",
       "4  2012-06-27-21-26        san francisco, california   \n",
       "\n",
       "                                offspring                       pets  \\\n",
       "0  doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "1  doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "2                                  NoKids                   has cats   \n",
       "3                       doesn't want kids                 likes cats   \n",
       "4                                  NoKids  likes dogs and likes cats   \n",
       "\n",
       "                                   religion  \\\n",
       "0     agnosticism and very serious about it   \n",
       "1  agnosticism but not too serious about it   \n",
       "2                                NoReligion   \n",
       "3                                NoReligion   \n",
       "4                                NoReligion   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks  \n",
       "0                                            english  \n",
       "1  english (fluently), spanish (poorly), french (...  \n",
       "2                               english, french, c++  \n",
       "3                           english, german (poorly)  \n",
       "4                                            english  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('raw_data/okcupid_nomissing.csv') \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.to_csv(filepath) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option number 2 -> imputing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.impute import SimpleImputer\\n\\nimputer = SimpleImputer(strategy=\"median\") \\n# Instantiate a SimpleImputer object with strategy of choice\\n\\nimputer.fit(data[[\\'RoofSurface\\']]) \\n# Call the \"fit\" method on the object\\n\\ndata[\\'RoofSurface\\'] = imputer.transform(data[[\\'RoofSurface\\']]) \\n# Call the \"transform\" method on the object\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") \n",
    "# Instantiate a SimpleImputer object with strategy of choice\n",
    "\n",
    "imputer.fit(data[['RoofSurface']]) \n",
    "# Call the \"fit\" method on the object\n",
    "\n",
    "data['RoofSurface'] = imputer.transform(data[['RoofSurface']]) \n",
    "# Call the \"transform\" method on the object\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amooora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
