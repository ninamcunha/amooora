{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-mAAJmfWc6I",
        "outputId": "1f6fd3fd-4127-4ee6-ab1f-edd941f32970"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.25.1\n",
            "Uninstalling numpy-1.25.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.11\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy-1.25.1.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libopenblas64_p-r0-7a851222.3.23.so\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled numpy-1.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.25.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "UZbJthy7Wk-y",
        "outputId": "f9ff9c23-8ddb-4592-99ea-36446445789f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.25.1\n",
            "  Using cached numpy-1.25.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Using cached numpy-1.25.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.25.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.1 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "cdb5c91a0a40459aba36517c8ec42b06"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import csv\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "3fpexDWGVolW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBU_CV5BYmnX",
        "outputId": "83a35a26-8ff2-4326-d687-6c7075c2ceaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "lGjQcNw-vmaK"
      },
      "outputs": [],
      "source": [
        "# folder containing the images\n",
        "image_folder = 'data'\n",
        "image_csv = 'images.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "EI38FUGSvqgL"
      },
      "outputs": [],
      "source": [
        "# collect file paths and names\n",
        "image_data = []\n",
        "for root, _, files in os.walk(image_folder):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')):\n",
        "            file_path = os.path.join(root, file)\n",
        "            image_data.append([file_path, file])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "4wPSKWTovuS_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423d06f9-7fae-4266-d505-10ba45418e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 150 image files.\n"
          ]
        }
      ],
      "source": [
        "# Debugging: Check if any images were found\n",
        "if not image_data:\n",
        "    print(f\"No image files found in the folder: {image_folder}\")\n",
        "else:\n",
        "    print(f\"Found {len(image_data)} image files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "hmuBRDEPzgHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffdea429-931b-4e21-911e-7665d9726fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created at: images.csv\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Write to CSV\n",
        "    with open(image_csv, mode='w', newline='', encoding='utf-8') as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow(['image_path', 'image_name'])  # Header\n",
        "        writer.writerows(image_data)\n",
        "    print(f\"CSV file created at: {image_csv}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error writing to CSV: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "jmt1EhaTzlyX"
      },
      "outputs": [],
      "source": [
        "# Load image paths from CSV\n",
        "df = pd.read_csv(\"images.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "b7cWiZZwztET"
      },
      "outputs": [],
      "source": [
        "# Make sure the csv has a column 'image_path'\n",
        "image_paths = df[\"image_path\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "MJe8X198zzHv"
      },
      "outputs": [],
      "source": [
        "# Load label names (male, female)\n",
        "label_lines = [line.rstrip() for line in tf.io.gfile.GFile(\"retrained_labels.txt\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "JFtbn0Z7zy8X"
      },
      "outputs": [],
      "source": [
        "# Load trained model\n",
        "with tf.io.gfile.GFile(\"retrained_graph.pb\", 'rb') as f:\n",
        "    graph_def = tf.compat.v1.GraphDef()\n",
        "    graph_def.ParseFromString(f.read())\n",
        "    _ = tf.import_graph_def(graph_def, name='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "ollGq_VRvJrt"
      },
      "outputs": [],
      "source": [
        "# ------------ Model for Age detection --------#\n",
        "age_weights = \"age_deploy.prototxt\"\n",
        "age_config = \"age_net.caffemodel\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "cq2_ICQ-vMRP"
      },
      "outputs": [],
      "source": [
        "# Model requirements for image\n",
        "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)',\n",
        "        '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
        "model_mean = (78.4263377603, 87.7689143744, 114.895847746)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "MLEPsXIovVTw"
      },
      "outputs": [],
      "source": [
        "# ------------- Model for face detection---------#\n",
        "face_detector = dlib.get_frontal_face_detector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "qxLtgTfD5xG9"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "predictions_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "NsHT9yB-3OJ-"
      },
      "outputs": [],
      "source": [
        "with tf.compat.v1.Session() as sess:\n",
        "    softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
        "\n",
        "    mssg = \"age\"\n",
        "    age = 0\n",
        "\n",
        "    for image_path in image_paths:\n",
        "\n",
        "        image_data = tf.io.gfile.GFile(image_path, 'rb').read()\n",
        "        predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data})\n",
        "\n",
        "        # START OF AGE DETECTION CODE\n",
        "\n",
        "        img = cv2.imread(image_path)\n",
        "        #print(img)\n",
        "\n",
        "\n",
        "        img = cv2.resize(img, (720, 640))\n",
        "        #print(img)\n",
        "\n",
        "        img.astype('uint8')\n",
        "        age_Net = cv2.dnn.readNet(age_config, age_weights)\n",
        "\n",
        "        frame = img.copy()\n",
        "\n",
        "        # storing the image dimensions\n",
        "        fH = img.shape[0]\n",
        "        fW = img.shape[1]\n",
        "\n",
        "        Boxes = [] # to store the face co-ordinates\n",
        "        # mssg = 'Face Detected' # to display on image\n",
        "\n",
        "        # converting to grayscale\n",
        "        img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # -------------detecting the faces--------------#\n",
        "        faces = face_detector(img_gray)\n",
        "\n",
        "        # If no faces are detected\n",
        "        if not faces:\n",
        "            mssg = 'No face detected'\n",
        "            # cv2.putText(img, f'{mssg}', (40, 40),cv2.FONT_HERSHEY_SIMPLEX, 2, (200), 2)\n",
        "            # Use cv2_imshow instead of cv2.imshow\n",
        "            # cv2_imshow(img)\n",
        "            # cv2.waitKey(0)\n",
        "\n",
        "        else:\n",
        "            # --------- Bounding Face ---------#\n",
        "            for face in faces:\n",
        "                x = face.left() # extracting the face coordinates\n",
        "                x = max(0, x)\n",
        "\n",
        "                y = face.top()\n",
        "                y = max(0, y)\n",
        "\n",
        "                x2 = face.right()\n",
        "                x2 = max(0, x2)\n",
        "\n",
        "                y2 = face.bottom()\n",
        "                y2 = max(0, y2)\n",
        "\n",
        "                # rescaling those coordinates for our image\n",
        "                box = [x, y, x2, y2]\n",
        "                Boxes.append(box)\n",
        "                cv2.rectangle(frame, (x, y), (x2, y2),(00, 200, 200), 2)\n",
        "\n",
        "            for box in Boxes:\n",
        "\n",
        "                # TEST!!!\n",
        "\n",
        "                face = frame[box[1]:box[3], box[0]:box[2]]\n",
        "\n",
        "                # ----- Image preprocessing --------#\n",
        "                blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), model_mean, swapRB=False)\n",
        "\n",
        "                # -------Age Prediction---------#\n",
        "                age_Net.setInput(blob)\n",
        "                age_preds = age_Net.forward()\n",
        "                age = ageList[age_preds[0].argmax()]\n",
        "\n",
        "                # cv2.putText(frame, f'{mssg}:{age}', (box[0],box[1] - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.8,(0, 255, 255), 2, cv2.LINE_AA)\n",
        "                # Use cv2_imshow instead of cv2.imshow\n",
        "                # cv2_imshow(frame)\n",
        "                # cv2.waitKey(0)\n",
        "\n",
        "                # TEST!!!\n",
        "                # print(age)\n",
        "\n",
        "          # This code is modified by Susobhan Akhuli\n",
        "\n",
        "\n",
        "        # END OF AGE DETECTION CODE\n",
        "\n",
        "\n",
        "        # Get the most confident prediction\n",
        "        top_label_index = predictions[0].argsort()[-1]\n",
        "        predicted_label = label_lines[top_label_index]\n",
        "\n",
        "        # Store results\n",
        "        predictions_list.append({\"image_path\": image_path, \"gender\": predicted_label, \"age\": age})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "boAJnLcF0lsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65732ecc-4a98-46b6-f7ae-d6449b07e947"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'image_path': 'data/1 (328).jpg', 'gender': 'male', 'age': 0},\n",
              " {'image_path': 'data/1 (307).jpg', 'gender': 'male', 'age': 0},\n",
              " {'image_path': 'data/1 (399).jpg', 'gender': 'female', 'age': 0},\n",
              " {'image_path': 'data/1 (284).jpg', 'gender': 'male', 'age': 0},\n",
              " {'image_path': 'data/1 (397).jpg', 'gender': 'male', 'age': '(38-43)'}]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "predictions_list[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Gs3EQEuI3lP3"
      },
      "outputs": [],
      "source": [
        "# Save predictions to CSV\n",
        "results_df = pd.DataFrame(predictions_list)\n",
        "results_df.to_csv(\"classified_images.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "SRO8WZay4CGp"
      },
      "outputs": [],
      "source": [
        "results_df.to_csv(\"/content/drive/My Drive/classified_images.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf data/"
      ],
      "metadata": {
        "id": "B-su3Raj5yof"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m8WmG9IWZ5DP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}